{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "familiar-repair",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "from joblib import dump, load\n",
    "from datetime import timedelta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import lightgbm as lightgbm\n",
    "\n",
    "# settings:\n",
    "numberOfInputWeeks = 3 # must be equal to the number of input weeks set in data preperator\n",
    "numberOfOutputWeeks = 4 # must be equal to the number of output week set in data preperator\n",
    "\n",
    "\n",
    "\n",
    "# data preperation\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "data = pd.read_csv(\"completedata.csv\")\n",
    "\n",
    "\n",
    "outputCategories = ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]\n",
    "numberOfOutputs = len(outputCategories)\n",
    "\n",
    "split = numberOfOutputs * numberOfOutputWeeks + 2\n",
    "train_features = data[data['category']=='train'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "train_labels = data[data['category']=='train'].iloc[:,-split:-2]\n",
    "\n",
    "validation1_features = data[data['category']=='validation 1'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation1_labels = data[data['category']=='validation 1'].iloc[:,-split:-2]\n",
    "validation2_features = data[data['category']=='validation 2'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation2_labels = data[data['category']=='validation 2'].iloc[:,-split:-2]\n",
    "validation1And2_labels = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,-split:-2]\n",
    "validation1And2_features = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "\n",
    "pip = Pipeline([('minmax_scaler', MinMaxScaler())])\n",
    "X_train = pip.fit_transform(train_features[train_features.columns].values)\n",
    "X_valid1 = pip.transform(validation1_features[train_features.columns].values)\n",
    "X_valid2 = pip.transform(validation2_features[train_features.columns].values)\n",
    "X_valid1And2 = pip.transform(validation1And2_features[train_features.columns].values)\n",
    "\n",
    "\n",
    "def generic1(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "def generic2(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic3(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic4(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic5(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic6(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic7(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic8(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[7], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "def genericKerasModel(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput):\n",
    "    if len(hiddenLayers) == 1:\n",
    "        return generic1(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 2:\n",
    "        return generic2(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 3:\n",
    "        return generic3(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 4:\n",
    "        return generic4(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 5:\n",
    "        return generic5(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 6:\n",
    "        return generic6(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 7:\n",
    "        return generic7(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    else:\n",
    "        return generic8(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"selectedEstimator\", help=\"computes estimator with given id\",type=int)\n",
    "parser.add_argument(\"iteration\", help=\"computes estimator with given id\",type=int)\n",
    "args = parser.parse_args()\n",
    "selectedEstimator = args.selectedEstimator\n",
    "iteration = args.iteration\n",
    "'''\n",
    "selectedEstimator = 40\n",
    "iteration = 1\n",
    "\n",
    "'''\n",
    "topComplete = pd.DataFrame()\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    temp = pd.read_csv(\"top_sklearn/\"+task+\".csv\")\n",
    "    temp['task'] = task\n",
    "    topComplete = topComplete.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "quality-practice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>week</th>\n",
       "      <th>model rmse 1</th>\n",
       "      <th>model rmse 2</th>\n",
       "      <th>last value baseline 1 rmse</th>\n",
       "      <th>last value baseline 2 rmse</th>\n",
       "      <th>modelClass</th>\n",
       "      <th>isMultiWeek</th>\n",
       "      <th>hiddenLayers</th>\n",
       "      <th>numberOfhiddenLayers</th>\n",
       "      <th>...</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>tol</th>\n",
       "      <th>rel. diff. to last value baseline 1</th>\n",
       "      <th>rel. diff. to last value baseline 2</th>\n",
       "      <th>rank1</th>\n",
       "      <th>rank2</th>\n",
       "      <th>overallRank</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.732536</td>\n",
       "      <td>1.403403</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196323</td>\n",
       "      <td>0.312038</td>\n",
       "      <td>25.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705502</td>\n",
       "      <td>1.406871</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225982</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>11.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.697129</td>\n",
       "      <td>1.409026</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235168</td>\n",
       "      <td>0.309282</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.769925</td>\n",
       "      <td>1.409175</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155302</td>\n",
       "      <td>0.309209</td>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.770077</td>\n",
       "      <td>1.404552</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155136</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>94.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.764738</td>\n",
       "      <td>1.412090</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.160994</td>\n",
       "      <td>0.307780</td>\n",
       "      <td>79.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.752477</td>\n",
       "      <td>1.412508</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174445</td>\n",
       "      <td>0.307575</td>\n",
       "      <td>64.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.673382</td>\n",
       "      <td>1.413410</td>\n",
       "      <td>0.911480</td>\n",
       "      <td>2.039944</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.261222</td>\n",
       "      <td>0.307133</td>\n",
       "      <td>3.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>death_inz_entries_7dayAverage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>26.850223</td>\n",
       "      <td>13.321967</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.418221</td>\n",
       "      <td>0.744453</td>\n",
       "      <td>38.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>26.933320</td>\n",
       "      <td>13.080883</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.416421</td>\n",
       "      <td>0.749077</td>\n",
       "      <td>46.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>27.047062</td>\n",
       "      <td>12.878751</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413956</td>\n",
       "      <td>0.752955</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>27.048801</td>\n",
       "      <td>12.874862</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413919</td>\n",
       "      <td>0.753029</td>\n",
       "      <td>57.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>27.069241</td>\n",
       "      <td>12.821616</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413476</td>\n",
       "      <td>0.754051</td>\n",
       "      <td>59.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>27.071447</td>\n",
       "      <td>13.102656</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>auto</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.413428</td>\n",
       "      <td>0.748660</td>\n",
       "      <td>61.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>modelClass=RandomForrest/isMultiWeek=True/n_es...</td>\n",
       "      <td>10</td>\n",
       "      <td>27.104061</td>\n",
       "      <td>13.260091</td>\n",
       "      <td>46.151967</td>\n",
       "      <td>52.131139</td>\n",
       "      <td>RandomForrest</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.412721</td>\n",
       "      <td>0.745640</td>\n",
       "      <td>63.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>workplaces_percent_change_from_baseline_7dayAv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modelId  week  model rmse 1  \\\n",
       "16  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.732536   \n",
       "19  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.705502   \n",
       "22  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.697129   \n",
       "24  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.769925   \n",
       "25  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.770077   \n",
       "26  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.764738   \n",
       "27  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.752477   \n",
       "28  modelClass=RandomForrest/isMultiWeek=True/n_es...    10      0.673382   \n",
       "0   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     26.850223   \n",
       "1   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     26.933320   \n",
       "2   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     27.047062   \n",
       "3   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     27.048801   \n",
       "4   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     27.069241   \n",
       "5   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     27.071447   \n",
       "6   modelClass=RandomForrest/isMultiWeek=True/n_es...    10     27.104061   \n",
       "\n",
       "    model rmse 2  last value baseline 1 rmse  last value baseline 2 rmse  \\\n",
       "16      1.403403                    0.911480                    2.039944   \n",
       "19      1.406871                    0.911480                    2.039944   \n",
       "22      1.409026                    0.911480                    2.039944   \n",
       "24      1.409175                    0.911480                    2.039944   \n",
       "25      1.404552                    0.911480                    2.039944   \n",
       "26      1.412090                    0.911480                    2.039944   \n",
       "27      1.412508                    0.911480                    2.039944   \n",
       "28      1.413410                    0.911480                    2.039944   \n",
       "0      13.321967                   46.151967                   52.131139   \n",
       "1      13.080883                   46.151967                   52.131139   \n",
       "2      12.878751                   46.151967                   52.131139   \n",
       "3      12.874862                   46.151967                   52.131139   \n",
       "4      12.821616                   46.151967                   52.131139   \n",
       "5      13.102656                   46.151967                   52.131139   \n",
       "6      13.260091                   46.151967                   52.131139   \n",
       "\n",
       "       modelClass  isMultiWeek  hiddenLayers  numberOfhiddenLayers  ...  \\\n",
       "16  RandomForrest         True           NaN                   NaN  ...   \n",
       "19  RandomForrest         True           NaN                   NaN  ...   \n",
       "22  RandomForrest         True           NaN                   NaN  ...   \n",
       "24  RandomForrest         True           NaN                   NaN  ...   \n",
       "25  RandomForrest         True           NaN                   NaN  ...   \n",
       "26  RandomForrest         True           NaN                   NaN  ...   \n",
       "27  RandomForrest         True           NaN                   NaN  ...   \n",
       "28  RandomForrest         True           NaN                   NaN  ...   \n",
       "0   RandomForrest         True           NaN                   NaN  ...   \n",
       "1   RandomForrest         True           NaN                   NaN  ...   \n",
       "2   RandomForrest         True           NaN                   NaN  ...   \n",
       "3   RandomForrest         True           NaN                   NaN  ...   \n",
       "4   RandomForrest         True           NaN                   NaN  ...   \n",
       "5   RandomForrest         True           NaN                   NaN  ...   \n",
       "6   RandomForrest         True           NaN                   NaN  ...   \n",
       "\n",
       "    max_features  n_estimators  min_samples_leaf  tol  \\\n",
       "16           0.5        1000.0               8.0  NaN   \n",
       "19           0.6        1000.0               8.0  NaN   \n",
       "22           0.7        1000.0               8.0  NaN   \n",
       "24           0.5        1000.0               4.0  NaN   \n",
       "25           0.4        1000.0               8.0  NaN   \n",
       "26           0.6        1000.0               1.0  NaN   \n",
       "27           0.7        1000.0               1.0  NaN   \n",
       "28           0.8        1000.0               8.0  NaN   \n",
       "0           auto        1000.0               8.0  NaN   \n",
       "1           auto        1000.0               2.0  NaN   \n",
       "2           auto        1000.0               NaN  NaN   \n",
       "3           auto         100.0               NaN  NaN   \n",
       "4           auto        1000.0               1.0  NaN   \n",
       "5           auto        1000.0               4.0  NaN   \n",
       "6            0.9        1000.0               8.0  NaN   \n",
       "\n",
       "    rel. diff. to last value baseline 1  rel. diff. to last value baseline 2  \\\n",
       "16                             0.196323                             0.312038   \n",
       "19                             0.225982                             0.310338   \n",
       "22                             0.235168                             0.309282   \n",
       "24                             0.155302                             0.309209   \n",
       "25                             0.155136                             0.311475   \n",
       "26                             0.160994                             0.307780   \n",
       "27                             0.174445                             0.307575   \n",
       "28                             0.261222                             0.307133   \n",
       "0                              0.418221                             0.744453   \n",
       "1                              0.416421                             0.749077   \n",
       "2                              0.413956                             0.752955   \n",
       "3                              0.413919                             0.753029   \n",
       "4                              0.413476                             0.754051   \n",
       "5                              0.413428                             0.748660   \n",
       "6                              0.412721                             0.745640   \n",
       "\n",
       "   rank1  rank2  overallRank  \\\n",
       "16  25.0   81.0         17.0   \n",
       "19  11.0   84.0         19.0   \n",
       "22   6.0   87.0         22.0   \n",
       "24  93.0   88.0         24.0   \n",
       "25  94.0   83.0         25.0   \n",
       "26  79.0   96.0         26.0   \n",
       "27  64.0   97.0         27.0   \n",
       "28   3.0   98.0         28.0   \n",
       "0   38.0   42.0          1.0   \n",
       "1   46.0   34.0          2.0   \n",
       "2   56.0   26.0          3.0   \n",
       "3   57.0   25.0          4.0   \n",
       "4   59.0   21.0          5.0   \n",
       "5   61.0   38.0          6.0   \n",
       "6   63.0   41.0          7.0   \n",
       "\n",
       "                                                 task  \n",
       "16                      death_inz_entries_7dayAverage  \n",
       "19                      death_inz_entries_7dayAverage  \n",
       "22                      death_inz_entries_7dayAverage  \n",
       "24                      death_inz_entries_7dayAverage  \n",
       "25                      death_inz_entries_7dayAverage  \n",
       "26                      death_inz_entries_7dayAverage  \n",
       "27                      death_inz_entries_7dayAverage  \n",
       "28                      death_inz_entries_7dayAverage  \n",
       "0   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "1   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "2   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "3   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "4   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "5   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "6   workplaces_percent_change_from_baseline_7dayAv...  \n",
       "\n",
       "[15 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = topComplete[topComplete['modelClass']!='RandomForrest']\n",
    "print(len(temp))\n",
    "print(len(topComplete[topComplete['modelClass']=='RandomForrest']))\n",
    "topComplete = temp.append(topComplete[topComplete['modelClass']=='RandomForrest'])\n",
    "#print(topComplete[topComplete['modelClass']=='RandomForrest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "serial-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-328de2b7841f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    157\u001b[0m                                       \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimatorId\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_samples_leaf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                                      )\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstructResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "numberOfEstimators = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "estimatorOfInterest = topComplete.iloc[selectedEstimator]\n",
    "\n",
    "\n",
    "#print(estimatorOfInterest)\n",
    "\n",
    "\n",
    "if (estimatorOfInterest['modelClass']=='MultiTaskLasso'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"MultiTaskLasso\",\n",
    "                  \"isMultiWeek\": True,\n",
    "                  \"alpha\": estimatorOfInterest['alpha'],\n",
    "                  \"tol\": tol,\n",
    "                  \"task\": estimatorOfInterest['task']\n",
    "                })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='Lasso'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"Lasso\",\n",
    "                  \"isMultiWeek\": True,\n",
    "                  \"alpha\": estimatorOfInterest['alpha'],\n",
    "                  \"tol\": tol,\n",
    "                  \"task\": estimatorOfInterest['task']\n",
    "                })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='ElasticNet'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                    {\n",
    "                      \"modelClass\": \"ElasticNet\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"alpha\": estimatorOfInterest['alpha'],\n",
    "                      \"l1_ratio\": estimatorOfInterest['l1_ratio'],\n",
    "                      \"tol\": tol,\n",
    "                      \"task\": estimatorOfInterest['task']\n",
    "                    })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='RandomForrest'):\n",
    "    \n",
    "    min_samples_leaf = 1\n",
    "    if not math.isnan(estimatorOfInterest['min_samples_leaf']):\n",
    "        min_samples_leaf = estimatorOfInterest['min_samples_leaf']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                    \"modelClass\": \"RandomForrest\",\n",
    "                    \"isMultiWeek\": True,\n",
    "                    \"n_estimators\": int(estimatorOfInterest['n_estimators']),\n",
    "                    \"max_features\": estimatorOfInterest['max_features'],\n",
    "                    \"min_samples_leaf\": int(min_samples_leaf),\n",
    "                    \"task\": estimatorOfInterest['task']\n",
    "                }\n",
    "            )  \n",
    "else:\n",
    "    raise ValueError('Tried to fit an unsupported estimator') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constructs and saves the results of a fitted estimator    \n",
    "def constructResults(estimator, task):\n",
    "   \n",
    "    # predictions for all weeks\n",
    "    predictions1 = pd.DataFrame(estimator.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]) \n",
    "    predictions2 = pd.DataFrame(estimator.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)])\n",
    "\n",
    "    # validation for all weeks\n",
    "    y_valid1 = validation1_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "    y_valid2 = validation2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "\n",
    "    resultsDf = pd.DataFrame()\n",
    "    # compute and safe results for every week\n",
    "    for outputWeekNumber in range(0,numberOfOutputWeeks):\n",
    "        # compute root mean squared error for validation sets\n",
    "        rmse1 = np.sqrt(mean_squared_error(predictions1[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid1[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        rmse2 = np.sqrt(mean_squared_error(predictions2[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid2[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        # safe the results and all model parameters\n",
    "        res = {}\n",
    "        if estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"max_features\": [estimators[estimatorId][\"max_features\"]],\n",
    "                 \"min_samples_leaf\": [estimators[estimatorId][\"min_samples_leaf\"]]\n",
    "                }               \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"ElasticNet\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"l1_ratio\": [estimators[estimatorId][\"l1_ratio\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError('Tried to save results for an unsupported estimator')\n",
    "        resultsDf = resultsDf.append(pd.DataFrame(data=res), ignore_index = True)\n",
    "    return resultsDf\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "estimatorId = 0\n",
    "\n",
    "# we just train one model per task\n",
    "task = estimators[estimatorId][\"task\"]\n",
    "# get train labels for all weeks\n",
    "y_train = train_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values\n",
    "\n",
    "if estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "    estimator = RandomForestRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                      max_features=estimators[estimatorId][\"max_features\"],\n",
    "                                      n_jobs=-1,\n",
    "                                      min_samples_leaf=estimators[estimatorId][\"min_samples_leaf\"]\n",
    "                                     )\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "    \n",
    "\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "    estimator = linear_model.Ridge(alpha=estimators[estimatorId][\"alpha\"], tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "    estimator = linear_model.Lasso(alpha=estimators[estimatorId][\"alpha\"], tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"ElasticNet\":\n",
    "    estimator = linear_model.ElasticNet(alpha=estimators[estimatorId][\"alpha\"],\n",
    "                                        l1_ratio=estimators[estimatorId][\"l1_ratio\"],\n",
    "                                        tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "    estimator = linear_model.MultiTaskLasso(alpha = estimators[estimatorId][\"alpha\"],\n",
    "                                           tol = estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "else:\n",
    "    raise ValueError('Tried to fit an unsupported estimator')  \n",
    "\n",
    "        \n",
    "    \n",
    "def generateModelId(dictionary):\n",
    "    modelId = \"\"\n",
    "    for key in dictionary.keys():\n",
    "        modelId = modelId + key +\"=\"+ str(dictionary[key]) +\"/\"\n",
    "    modelId = modelId[0:-1]\n",
    "    return modelId\n",
    "\n",
    "# add a modelId\n",
    "results[\"modelId\"] = generateModelId(estimators[estimatorId])\n",
    "results[\"modelIdNumber\"] = estimatorId\n",
    "                \n",
    "if not os.path.exists('results_selection_sklearn/'):\n",
    "    os.makedirs('results_selection_sklearn')\n",
    "results.to_csv(\"results_selection_sklearn/\"+str(selectedEstimator)+\"_iteration_\"+str(iteration)+\".csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-purpose",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

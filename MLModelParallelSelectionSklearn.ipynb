{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-repair",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# THIS FILE WAS USED TO TRAIN THE TOP SKLEARN MODELS IN PARALLEL ON LEONHARD\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "from joblib import dump, load\n",
    "from datetime import timedelta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import lightgbm as lightgbm\n",
    "\n",
    "# settings:\n",
    "numberOfInputWeeks = 3 # must be equal to the number of input weeks set in data preperator\n",
    "numberOfOutputWeeks = 4 # must be equal to the number of output week set in data preperator\n",
    "\n",
    "\n",
    "\n",
    "# data preperation\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "data = pd.read_csv(\"completedata.csv\")\n",
    "\n",
    "\n",
    "outputCategories = ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]\n",
    "numberOfOutputs = len(outputCategories)\n",
    "\n",
    "split = numberOfOutputs * numberOfOutputWeeks + 2\n",
    "train_features = data[data['category']=='train'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "train_labels = data[data['category']=='train'].iloc[:,-split:-2]\n",
    "\n",
    "validation1_features = data[data['category']=='validation 1'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation1_labels = data[data['category']=='validation 1'].iloc[:,-split:-2]\n",
    "validation2_features = data[data['category']=='validation 2'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation2_labels = data[data['category']=='validation 2'].iloc[:,-split:-2]\n",
    "validation1And2_labels = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,-split:-2]\n",
    "validation1And2_features = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "\n",
    "pip = Pipeline([('minmax_scaler', MinMaxScaler())])\n",
    "X_train = pip.fit_transform(train_features[train_features.columns].values)\n",
    "X_valid1 = pip.transform(validation1_features[train_features.columns].values)\n",
    "X_valid2 = pip.transform(validation2_features[train_features.columns].values)\n",
    "X_valid1And2 = pip.transform(validation1And2_features[train_features.columns].values)\n",
    "\n",
    "\n",
    "def generic1(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "def generic2(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic3(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic4(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic5(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic6(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic7(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic8(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[7], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "def genericKerasModel(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput):\n",
    "    if len(hiddenLayers) == 1:\n",
    "        return generic1(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 2:\n",
    "        return generic2(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 3:\n",
    "        return generic3(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 4:\n",
    "        return generic4(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 5:\n",
    "        return generic5(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 6:\n",
    "        return generic6(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 7:\n",
    "        return generic7(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    else:\n",
    "        return generic8(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"selectedEstimator\", help=\"computes estimator with given id\",type=int)\n",
    "parser.add_argument(\"iteration\", help=\"computes estimator with given id\",type=int)\n",
    "args = parser.parse_args()\n",
    "selectedEstimator = args.selectedEstimator\n",
    "iteration = args.iteration\n",
    "'''\n",
    "selectedEstimator = 40\n",
    "iteration = 1\n",
    "\n",
    "'''\n",
    "topComplete = pd.DataFrame()\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    temp = pd.read_csv(\"top_sklearn/\"+task+\".csv\")\n",
    "    temp['task'] = task\n",
    "    topComplete = topComplete.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-practice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp = topComplete[topComplete['modelClass']!='RandomForrest']\n",
    "print(len(temp))\n",
    "print(len(topComplete[topComplete['modelClass']=='RandomForrest']))\n",
    "topComplete = temp.append(topComplete[topComplete['modelClass']=='RandomForrest'])\n",
    "#print(topComplete[topComplete['modelClass']=='RandomForrest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "estimators = []\n",
    "numberOfEstimators = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "estimatorOfInterest = topComplete.iloc[selectedEstimator]\n",
    "\n",
    "\n",
    "#print(estimatorOfInterest)\n",
    "\n",
    "\n",
    "if (estimatorOfInterest['modelClass']=='MultiTaskLasso'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"MultiTaskLasso\",\n",
    "                  \"isMultiWeek\": True,\n",
    "                  \"alpha\": estimatorOfInterest['alpha'],\n",
    "                  \"tol\": tol,\n",
    "                  \"task\": estimatorOfInterest['task']\n",
    "                })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='Lasso'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"Lasso\",\n",
    "                  \"isMultiWeek\": True,\n",
    "                  \"alpha\": estimatorOfInterest['alpha'],\n",
    "                  \"tol\": tol,\n",
    "                  \"task\": estimatorOfInterest['task']\n",
    "                })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='ElasticNet'):\n",
    "    tol = 1e-4\n",
    "    if not math.isnan(estimatorOfInterest['tol']):\n",
    "        tol = estimatorOfInterest['tol']\n",
    "    \n",
    "    estimators.append(\n",
    "                    {\n",
    "                      \"modelClass\": \"ElasticNet\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"alpha\": estimatorOfInterest['alpha'],\n",
    "                      \"l1_ratio\": estimatorOfInterest['l1_ratio'],\n",
    "                      \"tol\": tol,\n",
    "                      \"task\": estimatorOfInterest['task']\n",
    "                    })\n",
    "    \n",
    "elif (estimatorOfInterest['modelClass']=='RandomForrest'):\n",
    "    \n",
    "    min_samples_leaf = 1\n",
    "    if not math.isnan(estimatorOfInterest['min_samples_leaf']):\n",
    "        min_samples_leaf = estimatorOfInterest['min_samples_leaf']\n",
    "    \n",
    "    estimators.append(\n",
    "                {\n",
    "                    \"modelClass\": \"RandomForrest\",\n",
    "                    \"isMultiWeek\": True,\n",
    "                    \"n_estimators\": int(estimatorOfInterest['n_estimators']),\n",
    "                    \"max_features\": estimatorOfInterest['max_features'],\n",
    "                    \"min_samples_leaf\": int(min_samples_leaf),\n",
    "                    \"task\": estimatorOfInterest['task']\n",
    "                }\n",
    "            )  \n",
    "else:\n",
    "    raise ValueError('Tried to fit an unsupported estimator') \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constructs and saves the results of a fitted estimator    \n",
    "def constructResults(estimator, task):\n",
    "   \n",
    "    # predictions for all weeks\n",
    "    predictions1 = pd.DataFrame(estimator.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]) \n",
    "    predictions2 = pd.DataFrame(estimator.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)])\n",
    "\n",
    "    # validation for all weeks\n",
    "    y_valid1 = validation1_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "    y_valid2 = validation2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "\n",
    "    resultsDf = pd.DataFrame()\n",
    "    # compute and safe results for every week\n",
    "    for outputWeekNumber in range(0,numberOfOutputWeeks):\n",
    "        # compute root mean squared error for validation sets\n",
    "        rmse1 = np.sqrt(mean_squared_error(predictions1[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid1[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        rmse2 = np.sqrt(mean_squared_error(predictions2[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid2[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        # safe the results and all model parameters\n",
    "        res = {}\n",
    "        if estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"max_features\": [estimators[estimatorId][\"max_features\"]],\n",
    "                 \"min_samples_leaf\": [estimators[estimatorId][\"min_samples_leaf\"]]\n",
    "                }               \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"ElasticNet\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"l1_ratio\": [estimators[estimatorId][\"l1_ratio\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError('Tried to save results for an unsupported estimator')\n",
    "        resultsDf = resultsDf.append(pd.DataFrame(data=res), ignore_index = True)\n",
    "    return resultsDf\n",
    "\n",
    "\n",
    "# training\n",
    "\n",
    "estimatorId = 0\n",
    "\n",
    "# we just train one model per task\n",
    "task = estimators[estimatorId][\"task\"]\n",
    "# get train labels for all weeks\n",
    "y_train = train_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values\n",
    "\n",
    "if estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "    estimator = RandomForestRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                      max_features=estimators[estimatorId][\"max_features\"],\n",
    "                                      n_jobs=-1,\n",
    "                                      min_samples_leaf=estimators[estimatorId][\"min_samples_leaf\"]\n",
    "                                     )\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "    \n",
    "\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "    estimator = linear_model.Ridge(alpha=estimators[estimatorId][\"alpha\"], tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "    estimator = linear_model.Lasso(alpha=estimators[estimatorId][\"alpha\"], tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"ElasticNet\":\n",
    "    estimator = linear_model.ElasticNet(alpha=estimators[estimatorId][\"alpha\"],\n",
    "                                        l1_ratio=estimators[estimatorId][\"l1_ratio\"],\n",
    "                                        tol=estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "    estimator = linear_model.MultiTaskLasso(alpha = estimators[estimatorId][\"alpha\"],\n",
    "                                           tol = estimators[estimatorId][\"tol\"])\n",
    "    estimator.fit(X_train,y_train)\n",
    "    \n",
    "    temp = constructResults(estimator, task)\n",
    "    temp['iteration'] = iteration\n",
    "    results = results.append(temp, ignore_index = True)\n",
    "else:\n",
    "    raise ValueError('Tried to fit an unsupported estimator')  \n",
    "\n",
    "        \n",
    "    \n",
    "def generateModelId(dictionary):\n",
    "    modelId = \"\"\n",
    "    for key in dictionary.keys():\n",
    "        modelId = modelId + key +\"=\"+ str(dictionary[key]) +\"/\"\n",
    "    modelId = modelId[0:-1]\n",
    "    return modelId\n",
    "\n",
    "# add a modelId\n",
    "results[\"modelId\"] = generateModelId(estimators[estimatorId])\n",
    "results[\"modelIdNumber\"] = estimatorId\n",
    "                \n",
    "if not os.path.exists('results_selection_sklearn/'):\n",
    "    os.makedirs('results_selection_sklearn')\n",
    "results.to_csv(\"results_selection_sklearn/\"+str(selectedEstimator)+\"_iteration_\"+str(iteration)+\".csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

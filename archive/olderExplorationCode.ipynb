{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Helper to get the top models for retraining\n",
    "pd.options.display.max_rows = 50\n",
    "rankedTasksDict['case_inz_entries_7dayAverage'].head(8).to_csv(\"top_sklearn/case_inz_entries_7dayAverage.csv\")\n",
    "rankedTasksDict['hosp_inz_entries_7dayAverage'].head(6).to_csv(\"top_sklearn/hosp_inz_entries_7dayAverage.csv\")\n",
    "temp = rankedTasksDict['death_inz_entries_7dayAverage']\n",
    "temp = temp[temp['overallRank']<=30]\n",
    "temp.to_csv(\"top_sklearn/death_inz_entries_7dayAverage.csv\")\n",
    "rankedTasksDict['workplaces_percent_change_from_baseline_7dayAverage'].head(7).to_csv(\"top_sklearn/workplaces_percent_change_from_baseline_7dayAverage.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# model selection process (relative performance scaling and maximizing distance to origin)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "resultsCopy = results.copy()\n",
    "resultsCopy = resultsCopy.drop_duplicates(['modelId'])\n",
    "resultsCopy.drop(['task','Unnamed: 0','week','last value baseline 1 rmse','last value baseline 2 rmse','model rmse 1','model rmse 2'], axis=1, inplace=True)\n",
    "attributesByModelId = resultsCopy.set_index('modelId')\n",
    "\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "resultsCopy = results.copy()\n",
    "resultsCopy = resultsCopy[['modelId','task','week','model rmse 1','model rmse 2','last value baseline 1 rmse','last value baseline 2 rmse']]\n",
    "\n",
    "# shift week number by one\n",
    "resultsCopy['week'] = resultsCopy['week']+1\n",
    "\n",
    "\n",
    "tasksDict = {}\n",
    "\n",
    "\n",
    "#'testPositvity_7dayAverageBoth',\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "             'hosp_inz_entries_7dayAverage',\n",
    "             'death_inz_entries_7dayAverage',\n",
    "             'testPositvity_7dayAverage',\n",
    "             'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "             'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    display(task)\n",
    "    # filter by task\n",
    "    taskResults = resultsCopy[resultsCopy['task']==task]\n",
    "    display(taskResults.shape)\n",
    "    \n",
    "    # sum up the same machine learning models over all 4 weeks\n",
    "    taskResults = taskResults.groupby(['modelId']).sum()\n",
    "    \n",
    "    # add relative score\n",
    "    taskResults['rel. diff. to last value baseline 1'] = (taskResults['last value baseline 1 rmse']-taskResults['model rmse 1'])/taskResults['last value baseline 1 rmse']\n",
    "    taskResults['rel. diff. to last value baseline 2'] = (taskResults['last value baseline 2 rmse']-taskResults['model rmse 2'])/taskResults['last value baseline 2 rmse']\n",
    "    taskResults = taskResults.sort_values(['model rmse 1'], ascending=True)\n",
    "    \n",
    "    \n",
    "    # add the attribute data for the models\n",
    "    taskResults = taskResults.join(attributesByModelId)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # filter so that only models which perform better than the baseline in both validation sets are consideres\n",
    "    taskResults = taskResults[(taskResults['rel. diff. to last value baseline 1'] >= 0) & (taskResults['rel. diff. to last value baseline 2'] >= 0)]\n",
    "    \n",
    "    \n",
    "    # only consider certain model classes\n",
    "    # taskResults = taskResults[(taskResults['modelClass'] != 'Keras')]\n",
    "    \n",
    "\n",
    "    # selection algorithm\n",
    "    scaler = MinMaxScaler()\n",
    "    taskResults['rel. diff. to last value baseline 1 scaled'] = scaler.fit_transform(np.array(taskResults['rel. diff. to last value baseline 1']).reshape(-1, 1))\n",
    "    taskResults['rel. diff. to last value baseline 2 scaled'] = scaler.fit_transform(np.array(taskResults['rel. diff. to last value baseline 2']).reshape(-1, 1))\n",
    "    taskResults['distanceFromOrigin'] = (taskResults['rel. diff. to last value baseline 1 scaled']**2 + taskResults['rel. diff. to last value baseline 2 scaled']**2)**(1/2)\n",
    "    taskResults.sort_values(by='distanceFromOrigin', ascending=False, inplace=True)\n",
    "\n",
    "    \n",
    "    # show the distribution of the relative performance for those models\n",
    "    taskResults[[\"rel. diff. to last value baseline 1\"]].plot.hist(by=None, bins=100, title=task+\" performance distribution for validation set 1\")\n",
    "    taskResults[[\"rel. diff. to last value baseline 2\"]].plot.hist(by=None, bins=100, title=task+\" performance distribution for validation set 2\")\n",
    "    plt.show()\n",
    "    #'modelIdNumber'\n",
    "    display(taskResults.head(10)[['rel. diff. to last value baseline 1','rel. diff. to last value baseline 2','distanceFromOrigin','modelClass','model rmse 1','model rmse 2','modelIdNumber','numberOfRanEpochs']])\n",
    "    \n",
    "    # safe the summarized model results in dictionary\n",
    "    tasksDict[task] = taskResults.copy()\n",
    "    \n",
    "    display(\"---------------------------------\")\n",
    "   \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "lists = []\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverageBoth',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    display(task)\n",
    "    df = tasksDict[task]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Keras\n",
    "    \n",
    "    #df = df[(df['isTwoWay']==False)\n",
    "    #       & (df['numberOfhiddenLayers']!=8)\n",
    "    #       & (df['isMultiWeek']==True)\n",
    "    #       & (df['numberOfhiddenLayers']!=7)\n",
    "    #       & (df['alpha']!=10)\n",
    "    #       & (df['alpha']!=100)\n",
    "    #       & (df['l1reg']!=10)\n",
    "    #       & (df['l1reg']!=100)\n",
    "    #       & (df['numberOfhiddenLayers']!=6)]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    for parameter in ['hiddelLayers']:\n",
    "    #for parameter in ['isMultiWeek','numberOfhiddenLayers','hiddelLayers','isTwoWay','l1reg','alpha','dropoutValue','learningRate']:\n",
    "        display(\"--------\"+parameter+\"-------\")\n",
    "        for error in ['distanceFromOrigin']:\n",
    "        #for error in ['model rmse 1', 'model rmse 2']:\n",
    "            lists.append(df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).describe().sort_values(by='max', axis=1, ascending=False).iloc[:,-40:].columns.tolist())\n",
    "            display(df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).describe().sort_values(by='max', axis=1, ascending=False).iloc[:,-40:].columns.tolist())\n",
    "            #display(df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).describe().sort_values(by='max', axis=1, ascending=False))\n",
    "            #display(df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).describe().sort_values(by='75%', axis=1, ascending=False))\n",
    "            #display(df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).describe().sort_values(by='50%', axis=1, ascending=False))\n",
    "            #df[df['modelClass']=='Keras'][[error,parameter]].pivot(columns=parameter, values=error).plot(kind=\"box\", title = parameter+\" effect \"+error, ylabel=error, xlabel=parameter, figsize=(10,5))\n",
    "            #plt.show()       \n",
    "    \n",
    "    \n",
    "    display(\"---------------------------------------------\")\n",
    "\n",
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "#display(intersection(lists[0],lists[1]))\n",
    "init = intersection(lists[0],lists[1])\n",
    "for i in range(1,len(lists)-1):\n",
    "    init = intersection(init, lists[i])\n",
    "display(init)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# inspecting models by hyperparamters\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    display(task)\n",
    "    df = tasksDict[task]\n",
    "    df = df[df['modelClass']=='Keras']\n",
    "    parameterOfInterest = 'numberOfhiddenLayers' #'isMultiWeek','numberOfhiddenLayers','hiddelLayers','isTwoWay','l1reg','alpha','dropoutValue','learningRate'\n",
    "    df = df[['model rmse 1','model rmse 2', parameterOfInterest]]\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    for possibleValue in df[parameterOfInterest].unique():\n",
    "        plt.scatter(df['model rmse 1'][df[parameterOfInterest] == possibleValue],\n",
    "                df['model rmse 2'][df[parameterOfInterest] == possibleValue],\n",
    "               marker='o',\n",
    "               label=possibleValue,\n",
    "               alpha=0.4)\n",
    "    plt.xlabel('model rmse 1')\n",
    "    plt.ylabel('model rmse 2')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "   \n",
    "    display(\"---------------------------------------------\")\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# all models plot\n",
    "for task in ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]:\n",
    "    display(task)\n",
    "    df = tasksDict[task]\n",
    "    df = df[['model rmse 1','model rmse 2','modelClass']]\n",
    "    display(df.shape)\n",
    "    \n",
    "    df = df[(df['model rmse 1'] < df['model rmse 1'].mean()) & \n",
    "           (df['model rmse 2'] < df['model rmse 2'].mean())\n",
    "           ]\n",
    "    df = df[(df['model rmse 1'] < df['model rmse 1'].mean() + 3*df['model rmse 1'].std()) & \n",
    "           (df['model rmse 2'] < df['model rmse 2'].mean() + 3*df['model rmse 2'].std())\n",
    "           ]\n",
    "    display(df.shape)\n",
    "    #display(df['model rmse 1'].mean())\n",
    "    #+ 3*df['model rmse 1'].std()\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'Keras'],\n",
    "            df['model rmse 2'][df.modelClass == 'Keras'],\n",
    "           marker='o',\n",
    "           color='blue',\n",
    "           label='Keras',\n",
    "           alpha=0.2)\n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'LGBM'],\n",
    "            df['model rmse 2'][df.modelClass == 'LGBM'],\n",
    "           marker='o',\n",
    "           color='red',\n",
    "           label='LGBM',\n",
    "           alpha=0.4)\n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'XGB'],\n",
    "            df['model rmse 2'][df.modelClass == 'XGB'],\n",
    "           marker='o',\n",
    "           color='green',\n",
    "           label='XGB',\n",
    "           alpha=0.4)\n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'RandomForrest'],\n",
    "            df['model rmse 2'][df.modelClass == 'RandomForrest'],\n",
    "           marker='o',\n",
    "           color='yellow',\n",
    "           label='RandomForrest',\n",
    "           alpha=0.4)\n",
    "    \n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'Ridge'],\n",
    "            df['model rmse 2'][df.modelClass == 'Ridge'],\n",
    "           marker='o',\n",
    "           label='Ridge',\n",
    "           alpha=0.4)\n",
    "    \n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'Lasso'],\n",
    "            df['model rmse 2'][df.modelClass == 'Lasso'],\n",
    "           marker='o',\n",
    "           label='Lasso',\n",
    "           alpha=0.4)\n",
    "    \n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'MultiTaskLasso'],\n",
    "            df['model rmse 2'][df.modelClass == 'MultiTaskLasso'],\n",
    "           marker='o',\n",
    "           label='MultiTaskLasso',\n",
    "           alpha=0.4)\n",
    "    \n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'SVR'],\n",
    "            df['model rmse 2'][df.modelClass == 'SVR'],\n",
    "           marker='o',\n",
    "           label='SVR',\n",
    "           alpha=0.4)\n",
    "    \n",
    "    \n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'SGD'],\n",
    "            df['model rmse 2'][df.modelClass == 'SGD'],\n",
    "           marker='o',\n",
    "           label='SGD',\n",
    "           alpha=0.4)\n",
    "    ''\n",
    "    plt.scatter(df['model rmse 1'][df.modelClass == 'KernelRidge'],\n",
    "            df['model rmse 2'][df.modelClass == 'KernelRidge'],\n",
    "           marker='o',\n",
    "           label='KernelRidge',\n",
    "           alpha=0.4)\n",
    "   \n",
    "    plt.xlabel('model rmse 1')\n",
    "    plt.ylabel('model rmse 2')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "   \n",
    "    display(\"---------------------------------------------\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# SINGLE VS. MULTI OUTPUT (for all weeks and for all targets plot single, multi, baseline per model class)\n",
    "for modelClass in ['RandomForrest']: # 'RandomForrest', 'Lasso''Keras' ,'SGD','KernelRidge','MultiTaskLasso','MLP','KernelRidge','XGB','LGBM','Ridge','SVR','Keras'\n",
    "    for category in outputCategories:\n",
    "        merged1 = pd.DataFrame()\n",
    "        merged2 = pd.DataFrame()\n",
    "        for week in range(0,numberOfOutputWeeks):\n",
    "            temp = df[(df['week']==week)&(df['task']==category)&(df['modelClass']==modelClass)].groupby(['isMultiWeek']).apply(lambda x: x.sort_values([\"rel. diff. to last value baseline 1\"], ascending=False)).reset_index(drop=True)\n",
    "            temp = temp.groupby(['isMultiWeek']).head(1)\n",
    "            temp1 = temp[['model rmse 1', 'last value baseline 1 rmse', 'isMultiWeek']].set_index('isMultiWeek')\n",
    "            temp2 = temp[['model rmse 2', 'last value baseline 2 rmse', 'isMultiWeek']].set_index('isMultiWeek')\n",
    "            new_row1 = pd.Series(data={'rmse':temp1['last value baseline 1 rmse'].values[0]}, name='baseline')\n",
    "            new_row2 = pd.Series(data={'rmse':temp2['last value baseline 2 rmse'].values[0]}, name='baseline')\n",
    "            temp1.rename(columns = {'model rmse 1':'rmse'}, inplace = True)\n",
    "            temp2.rename(columns = {'model rmse 2':'rmse'}, inplace = True)\n",
    "            temp1.drop(['last value baseline 1 rmse'], inplace=True, axis=1)\n",
    "            temp2.drop(['last value baseline 2 rmse'], inplace=True, axis=1)\n",
    "            temp1 = temp1.append(new_row1, ignore_index=False) #.sort_values(['rsme'], ascending=False)\n",
    "            temp2 = temp2.append(new_row2, ignore_index=False)\n",
    "            temp1.rename(columns = {'rmse':str(week+1)}, inplace=True)\n",
    "            temp2.rename(columns = {'rmse':str(week+1)}, inplace=True)\n",
    "            merged1 = merged1.append(temp1.transpose())\n",
    "            merged2 = merged2.append(temp2.transpose())\n",
    "            #temp.plot(kind='bar', title=modelClass+\"_\"+category+\"_\"+\"week_\"+str(week))\n",
    "            #plt.show()\n",
    "        merged1.plot(kind='line',title=modelClass+\" \"+category +\" (validation set 1 scores)\",ylabel='rmse', xlabel=\"week\", figsize=(20,10))\n",
    "        merged2.plot(kind='line',title=modelClass+\" \"+category +\" (validation set 2 scores)\",ylabel='rmse', xlabel=\"week\", figsize=(20,10))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# MODEL COMPARISON (for all weeks and for all target best estimator per model class)\n",
    "pd.options.display.max_rows = 11\n",
    "for category in outputCategories:\n",
    "    mergedAbs1 = pd.DataFrame()\n",
    "    mergedAbs2 = pd.DataFrame()\n",
    "    mergedRel1 = pd.DataFrame()\n",
    "    mergedRel2 = pd.DataFrame()\n",
    "    for week in range(0,numberOfOutputWeeks):\n",
    "        temp = df[(df['week']==week)&(df['task']==category)].groupby(['modelClass']).apply(lambda x: x.sort_values([\"rel. diff. to last value baseline 1\"], ascending=False)).reset_index(drop=True)\n",
    "        temp = temp.groupby(['modelClass']).head(1) #.sort_values(['rel. diff. to last value baseline 1'], ascending=False)\n",
    "        \n",
    "        # for absolut values plot\n",
    "        temp1V1 = temp[['modelClass','model rmse 1','last value baseline 1 rmse']].set_index('modelClass')\n",
    "        temp1V2 = temp[['modelClass','model rmse 2','last value baseline 2 rmse']].set_index('modelClass') \n",
    "        new_row1 = pd.Series(data={'rmse':temp1V1['last value baseline 1 rmse'].values[0]}, name='baseline')\n",
    "        new_row2 = pd.Series(data={'rmse':temp1V2['last value baseline 2 rmse'].values[0]}, name='baseline')\n",
    "        temp1V1.rename(columns = {'model rmse 1':'rmse'}, inplace = True)\n",
    "        temp1V2.rename(columns = {'model rmse 2':'rmse'}, inplace = True)\n",
    "        temp1V1.drop(['last value baseline 1 rmse'], inplace=True, axis=1)\n",
    "        temp1V2.drop(['last value baseline 2 rmse'], inplace=True, axis=1)\n",
    "        temp1V1 = temp1V1.append(new_row1, ignore_index=False).sort_values(['rmse'], ascending=False)\n",
    "        temp1V2 = temp1V2.append(new_row2, ignore_index=False).sort_values(['rmse'], ascending=False)\n",
    "        temp1V1.rename(columns = {'rmse':str(week+1)}, inplace=True)\n",
    "        temp1V2.rename(columns = {'rmse':str(week+1)}, inplace=True)\n",
    "        mergedAbs1 = mergedAbs1.append(temp1V1.transpose())\n",
    "        mergedAbs2 = mergedAbs2.append(temp1V2.transpose())\n",
    "\n",
    "        # for relative to baseline plot\n",
    "        temp2V1 = temp[['modelClass','rel. diff. to last value baseline 1']].set_index('modelClass')\n",
    "        temp2V2 = temp[['modelClass','rel. diff. to last value baseline 2']].set_index('modelClass')\n",
    "        temp2V1.rename(columns = {'rel. diff. to last value baseline 1':'rel. diff. to baseline'}, inplace = True)\n",
    "        temp2V2.rename(columns = {'rel. diff. to last value baseline 2':'rel. diff. to baseline'}, inplace = True)\n",
    "        temp2V1 = temp2V1.sort_values(['rel. diff. to baseline'], ascending=True)\n",
    "        temp2V2 = temp2V2.sort_values(['rel. diff. to baseline'], ascending=True)\n",
    "        temp2V1.rename(columns = {'rel. diff. to baseline':str(week+1)}, inplace=True)\n",
    "        temp2V2.rename(columns = {'rel. diff. to baseline':str(week+1)}, inplace=True)\n",
    "        mergedRel1 = mergedRel1.append(temp2V1.transpose())\n",
    "        mergedRel2 = mergedRel2.append(temp2V2.transpose())\n",
    "\n",
    "    mergedAbs1.plot(kind='line',title=category + \" (validation set 1 scores)\",ylabel='rmse', xlabel=\"week\", figsize=(20,10))\n",
    "    mergedAbs2.plot(kind='line',title=category + \" (validation set 2 scores)\",ylabel='rmse', xlabel=\"week\", figsize=(20,10))\n",
    "    mergedRel1.plot(kind='line',title=category + \" (validation set 1 scores)\",ylabel='rel. diff. to baseline', xlabel=\"week\", figsize=(20,10))\n",
    "    mergedRel2.plot(kind='line',title=category + \" (validation set 2 scores)\",ylabel='rel. diff. to baseline', xlabel=\"week\", figsize=(20,10))\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# OVERVIEW (for all weeks best estimator per target)\n",
    "df = results.copy()\n",
    "merged1 = pd.DataFrame()\n",
    "merged2 = pd.DataFrame()\n",
    "for week in range(0,numberOfOutputWeeks):\n",
    "    temp = df[df['week']==week].groupby(['task']).apply(lambda x: x.sort_values(['rel. diff. to last value baseline 1'], ascending=False)).reset_index(drop=True)\n",
    "    temp = temp.groupby(['task']).head(1)\n",
    "    temp1 = temp[['task','rel. diff. to last value baseline 1']].set_index('task')\n",
    "    temp2 = temp[['task','rel. diff. to last value baseline 2']].set_index('task')\n",
    "    temp1.rename(columns = {'rel. diff. to last value baseline 1': str(week+1)}, inplace = True)\n",
    "    temp2.rename(columns = {'rel. diff. to last value baseline 2': str(week+1)}, inplace = True)\n",
    "    merged1 = merged1.append(temp1.transpose())\n",
    "    merged2 = merged2.append(temp2.transpose())\n",
    "    #.sort_values(['rsme'], ascending=False)\n",
    "    #temp.plot(kind='bar', title=\"week_\"+str(week))\n",
    "    #plt.show()\n",
    "    \n",
    "merged1.plot(kind='line', title=\"validation set 1 scores\", ylabel='rel. diff. to baseline', xlabel=\"week\", figsize=(10,5))\n",
    "merged2.plot(kind='line', title=\"validation set 2 scores\", ylabel='rel. diff. to baseline', xlabel=\"week\", figsize=(10,5))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file1 = open('output.log', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "\n",
    "\n",
    "estimatorErrors = []\n",
    "\n",
    "for line in Lines:\n",
    "    estimatorErrors.append(int(line[32:-11]))\n",
    "\n",
    "   \n",
    "\n",
    "with open('erstimatorErrors.txt', 'w') as f:\n",
    "    for e in estimatorErrors:\n",
    "        f.write(str(e)+\"\\n\")\n",
    "display(len(estimatorErrors))\n",
    "\n",
    "\n",
    "for e in estimatorErrors[0:125]:\n",
    "    display(str(e)+\": \"+str(estimators[e]))\n",
    "  \n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

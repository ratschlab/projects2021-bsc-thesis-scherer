{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request, json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from icalendar import Calendar\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code section loads all needed data to a local folder and immediately creates a backup\n",
    "\n",
    "# get newest available string to download FOPH data\n",
    "zipurl = ''\n",
    "with urllib.request.urlopen(\"https://www.covid19.admin.ch/api/data/context\") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    zipurl = data[\"sources\"][\"zip\"][\"csv\"]\n",
    "\n",
    "# download the FOPH data (use this data also for the virus variants)\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/FOPH')\n",
    "\n",
    "# download the Google Mobility data\n",
    "zipurl = 'https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/GoogleMobility')\n",
    "\n",
    "# download the Intervista Mobility data\n",
    "zipurl = 'https://www.intervista.ch/media/2020/03/Download_Mobilit%C3%A4ts-Monitoring_Covid-19.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/IntervistaMobility')\n",
    "\n",
    "# KOF strigency index data\n",
    "df = pd.read_csv('https://datenservice.kof.ethz.ch/api/v1/public/sets/stringency_plus_web?mime=csv&df=Y-m-d')\n",
    "if not os.path.exists('data/KOF'):\n",
    "    os.makedirs('data/KOF')\n",
    "df.to_csv('data/KOF/KOFStrigencyIndex.csv')\n",
    "      \n",
    "# Oxford COVID-19 Government Response Tracker\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv')\n",
    "if not os.path.exists('data/Oxford'):\n",
    "    os.makedirs('data/Oxford')\n",
    "df.to_csv('data/Oxford/OxfordStrigencyIndex.csv')\n",
    "\n",
    "# TODO: weather (open weather api key requested, but i will only get past data maximum one year back)\n",
    "\n",
    "# ==================== THE MANUAL WORK ==================\n",
    "\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "cantonNames = ['aargau','appenzell-innerrhoden','appenzell-ausserrhoden','bern','basel-land','basel-stadt','freiburg','genf','glarus','graubuenden','jura','luzern','neuenburg','nidwalden','obwalden','sankt-gallen','schaffhausen','solothurn','schwyz','thurgau','tessin','uri','waadt','wallis','zug','zuerich']\n",
    "# create dictionary\n",
    "d = dict(zip(cantonKeys, cantonNames))\n",
    "\n",
    "holydayVacationTable = pd.DataFrame(index=pd.date_range(start='1/1/2020', end='31/12/2021'), columns = cantonKeys)\n",
    "holydayVacationTable[cantonKeys] = 0\n",
    "\n",
    "\n",
    "def fillCantonHolidays(cantonKey, filename):\n",
    "    # extract dates from file and fill in all special holidays\n",
    "    file = open(filename, 'rb')\n",
    "    cal = Calendar.from_ical(file.read())\n",
    "    for e in cal.walk('vevent'):\n",
    "        start = e['DTSTART'].to_ical().decode('utf-8')\n",
    "        parsedDate = datetime.datetime.strptime(start, '%Y%m%d')\n",
    "        holydayVacationTable[cantonKey][parsedDate] = 1  \n",
    "    \n",
    "\n",
    "def fillCantonVacation(cantonKey, filename):\n",
    "    # extract dates from file\n",
    "    file = open(filename, 'rb')\n",
    "    cal = Calendar.from_ical(file.read())\n",
    "    for e in cal.walk('vevent'):\n",
    "        startDate = e['DTSTART'].to_ical().decode('utf-8')\n",
    "        endDate = e['DTEND'].to_ical().decode('utf-8')\n",
    "        parsedStartDate = datetime.datetime.strptime(startDate, '%Y%m%d')\n",
    "        parsedEndDate = datetime.datetime.strptime(endDate, '%Y%m%d') \n",
    "        if parsedEndDate > datetime.datetime(2021, 12, 31):\n",
    "            parsedEndDate = datetime.datetime(2021, 12, 31)\n",
    "        r = pd.date_range(start=parsedStartDate, end=parsedEndDate)\n",
    "        holydayVacationTable[cantonKey][r] = 1\n",
    "        \n",
    "        \n",
    "for c in cantonKeys:\n",
    "    # fill the canton holidays which are only single days\n",
    "    for p in ['static_data/holidays/2020/', 'static_data/holidays/2021/']:\n",
    "        matches = [match for match in os.listdir(p) if d[c] in match]\n",
    "        filename = matches[0]\n",
    "        path = p + filename\n",
    "        fillCantonHolidays(c, path)\n",
    "       \n",
    "    # fill the school vacations which have a start and end date\n",
    "    for p in ['static_data/vacations/2020/', 'static_data/vacations/2021/']:\n",
    "        matches = [match for match in os.listdir(p) if d[c] in match]\n",
    "        filename = matches[0]\n",
    "        path = p + filename\n",
    "        fillCantonVacation(c, path)\n",
    "    \n",
    "# offset = 6 gets all sundays, offset 5 all saturdays\n",
    "def getDays(year, offset):\n",
    "   d = date(year, 1, 1)                    \n",
    "   d += timedelta(days = offset - d.weekday())  \n",
    "   while d.year == year:\n",
    "      yield d\n",
    "      d += timedelta(days = 7)\n",
    "\n",
    "listOfSaturdaysSundays = []\n",
    "for year in [2020,2021]:\n",
    "    for weekday in [5,6]:\n",
    "        for day in getDays(year, weekday):\n",
    "           listOfSaturdaysSundays.append(day)\n",
    "\n",
    "\n",
    "for e in listOfSaturdaysSundays:\n",
    "    holydayVacationTable.loc[e]=1\n",
    "\n",
    "\n",
    "if not os.path.exists('data/HolidayVacation'):\n",
    "    os.makedirs('data/HolidayVacation')\n",
    "holydayVacationTable.to_csv('data/HolidayVacation/HolidayVacation.csv')\n",
    "# ========================================================\n",
    "\n",
    "\n",
    "# TODO: measures.csv cantonal/federal\n",
    "\n",
    "# International data for bordering countries (only weekly because germany, also earliest data point is from week 13 2020)\n",
    "df = pd.read_csv('https://opendata.ecdc.europa.eu/covid19/subnationalcaseweekly/csv')\n",
    "if not os.path.exists('data/ECDC'):\n",
    "    os.makedirs('data/ECDC')\n",
    "df.to_csv('data/ECDC/ECDCsubnationalcaseweekly.csv')\n",
    "\n",
    "# International data for bordering countries (only country level data)\n",
    "df = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n",
    "if not os.path.exists('data/OWID'):\n",
    "    os.makedirs('data/OWID')\n",
    "df.to_csv('data/OWID/OWIDcoviddata.csv')\n",
    "\n",
    "# create a backup of the data we just loaded\n",
    "if not os.path.exists('backups'):\n",
    "    os.makedirs('backups')\n",
    "now = datetime.datetime.now()\n",
    "backupname = now.strftime(\"backup-%Y-%m-%d-%H-%M-%S\")\n",
    "shutil.copytree('data', 'backups/'+backupname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor m in measures.columns:\\n    measures.plot(kind='line', y=m, figsize=(15,15))\\n    #measures.reset_index().plot.scatter(x = 'Time', y = m)\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#======================== construct the federal measures ================\n",
    "columnNames = pd.read_excel('static_data/measures/measures.xlsx', sheet_name = 'Federal').columns\n",
    "measures = pd.read_excel('static_data/measures/measures.xlsx', sheet_name = 'Federal', skiprows=6, names=columnNames)\n",
    "\n",
    "measures = measures.set_index('Time')\n",
    "\n",
    "for day in pd.date_range(start=datetime.datetime(2020, 1, 1), end=datetime.datetime(2021, 12, 31)):\n",
    "    if not day in measures.index:\n",
    "        measures.loc[day] = [float('NaN')] * len(measures.columns)\n",
    "\n",
    "measures = measures.sort_index()\n",
    "\n",
    "# propagate the update changes to all other days\n",
    "for j in measures.columns: #iterate over columns\n",
    "    dailyMeasureLevel = 0\n",
    "    for i in measures.index: #iterate over rows #get actual cell value\n",
    "        if math.isnan(measures.loc[i, j]):\n",
    "            measures.loc[i, j] = dailyMeasureLevel\n",
    "        else:\n",
    "            dailyMeasureLevel = measures.loc[i, j]\n",
    "'''\n",
    "for m in measures.columns:\n",
    "    measures.plot(kind='line', y=m, figsize=(15,15))\n",
    "    #measures.reset_index().plot.scatter(x = 'Time', y = m)\n",
    "    plt.show()\n",
    "'''\n",
    "#======================== construct the cantonal measures ================\n",
    "# todo, also think of the exception for some canton in december\n",
    "# copy the federal measures and use max function (with some exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

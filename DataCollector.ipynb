{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request, json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from icalendar import Calendar\n",
    "import datetime\n",
    "from datetime import date, timedelta, timezone\n",
    "pd.options.display.max_rows = None\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "# special mapping for weather API\n",
    "#['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "#[\"Aarau\",\"Appenzell\",\"Herisau\",\"Bern\",\"Liestal\",\"Basel\",\"Fribourg\",\"Geneve\",\"2660594\",\"Chur\",\"Delemont\",\"Luzern\",\"Neuchatel\",\"Stans\",\"Sarnen\",\"Sankt Gallen\", \"Schaffhausen\", \"Olten\",\"Schwyz\",\"Frauenfeld\",\"Bellinzona\",\"2661780\",\"Lausanne\",\"Sion\",\"Zug\",\"Zurich\"]\n",
    "weatherDictionary = dict(zip(cantonKeys,[2661881,2661740,2660365,2661552,2659891,2661604,2660718,2660646,2660594,2661169,2661035,2659811,2659496,2658504,2658786,2658822,2658761,2658564,2658665,2660727,2661567,2661780,2659994,2658576,2657908,2657896]))\n",
    "apiKey = \"0077c15de8e01960cc024a8b11751ead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOPH data downloaded (8.230000019073486 seconds)\n"
     ]
    }
   ],
   "source": [
    "# download FOPH data\n",
    "start = time.time()\n",
    "# get newest available string to download FOPH data\n",
    "zipurl = ''\n",
    "with urllib.request.urlopen(\"https://www.covid19.admin.ch/api/data/context\") as url:\n",
    "    data = json.loads(url.read().decode())\n",
    "    zipurl = data[\"sources\"][\"zip\"][\"csv\"]\n",
    "\n",
    "# download the FOPH data (use this data also for the virus variants)\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/FOPH')\n",
    "\n",
    "print(\"FOPH data downloaded (%s seconds)\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google mobility data downloaded (13.960783958435059 seconds)\n"
     ]
    }
   ],
   "source": [
    "# download the Google mobility data\n",
    "start = time.time()\n",
    "zipurl = 'https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/GoogleMobility')\n",
    "\n",
    "print(\"Google mobility data downloaded (%s seconds)\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervista mobility data downloaded (5.805161952972412 seconds)\n"
     ]
    }
   ],
   "source": [
    "# download intervista mobility data\n",
    "start = time.time()\n",
    "zipurl = 'https://www.intervista.ch/media/2020/03/Download_Mobilit%C3%A4ts-Monitoring_Covid-19.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data/IntervistaMobility')\n",
    "print(\"Intervista mobility data downloaded (%s seconds)\" % (time.time() - start))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KOF strigency data downloaded (0.6547150611877441 seconds)\n"
     ]
    }
   ],
   "source": [
    "# download KOF strigency index data\n",
    "start = time.time()\n",
    "df = pd.read_csv('https://datenservice.kof.ethz.ch/api/v1/public/sets/stringency_plus_web?mime=csv&df=Y-m-d')\n",
    "if not os.path.exists('data/KOF'):\n",
    "    os.makedirs('data/KOF')\n",
    "df.to_csv('data/KOF/KOFStrigencyIndex.csv')\n",
    "print(\"KOF strigency data downloaded (%s seconds)\" % (time.time() - start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holyday/Vacation data computed (0.6003077030181885 seconds)\n"
     ]
    }
   ],
   "source": [
    "# compute holydays and vacations per canton from ical files (has only to run once to create holydayvacation.csv)\n",
    "\n",
    "start = time.time()\n",
    "holydayVacationTable = pd.DataFrame(index=pd.date_range(start='1/1/2020', end='31/12/2021'), columns = cantonKeys)\n",
    "holydayVacationTable.index = pd.to_datetime(holydayVacationTable.index) \n",
    "holydayVacationTable[cantonKeys] = 0\n",
    "\n",
    "\n",
    "def fillCantonHolidays(cantonKey, filename):\n",
    "    # extract dates from file and fill in all special holidays\n",
    "    file = open(filename, 'rb')\n",
    "    cal = Calendar.from_ical(file.read())\n",
    "    for e in cal.walk('vevent'):\n",
    "        start = e['DTSTART'].to_ical().decode('utf-8')\n",
    "        parsedDate = datetime.datetime.strptime(start, '%Y%m%d')\n",
    "        holydayVacationTable[cantonKey][parsedDate] = 1  \n",
    "    \n",
    "\n",
    "def fillCantonVacation(cantonKey, filename):\n",
    "    # extract dates from file\n",
    "    file = open(filename, 'rb')\n",
    "    cal = Calendar.from_ical(file.read())\n",
    "    for e in cal.walk('vevent'):\n",
    "        startDate = e['DTSTART'].to_ical().decode('utf-8')\n",
    "        endDate = e['DTEND'].to_ical().decode('utf-8')\n",
    "        parsedStartDate = datetime.datetime.strptime(startDate, '%Y%m%d')\n",
    "        parsedEndDate = datetime.datetime.strptime(endDate, '%Y%m%d') \n",
    "        if parsedEndDate > datetime.datetime(2021, 12, 31):\n",
    "            parsedEndDate = datetime.datetime(2021, 12, 31)\n",
    "        r = pd.date_range(start=parsedStartDate, end=parsedEndDate)\n",
    "        holydayVacationTable[cantonKey][r] = 1\n",
    "\n",
    "        \n",
    "# special mapping for holiday and vacation file names\n",
    "vacHolyDictionary = dict(zip(cantonKeys, ['aargau','appenzell-innerrhoden','appenzell-ausserrhoden','bern','basel-land','basel-stadt','freiburg','genf','glarus','graubuenden','jura','luzern','neuenburg','nidwalden','obwalden','sankt-gallen','schaffhausen','solothurn','schwyz','thurgau','tessin','uri','waadt','wallis','zug','zuerich']))       \n",
    "for c in cantonKeys:\n",
    "    # fill the canton holidays which are only single days\n",
    "    for p in ['static_data/holidays/2020/', 'static_data/holidays/2021/']:\n",
    "        matches = [match for match in os.listdir(p) if vacHolyDictionary[c] in match]\n",
    "        filename = matches[0]\n",
    "        path = p + filename\n",
    "        fillCantonHolidays(c, path)\n",
    "       \n",
    "    # fill the school vacations which have a start and end date\n",
    "    for p in ['static_data/vacations/2020/', 'static_data/vacations/2021/']:\n",
    "        matches = [match for match in os.listdir(p) if vacHolyDictionary[c] in match]\n",
    "        filename = matches[0]\n",
    "        path = p + filename\n",
    "        fillCantonVacation(c, path)\n",
    "\n",
    "\n",
    "# offset = 6 gets all sundays, offset 5 all saturdays\n",
    "def getDays(year, offset):\n",
    "   d = date(year, 1, 1)                    \n",
    "   d += timedelta(days = offset - d.weekday())  \n",
    "   while d.year == year:\n",
    "      yield d\n",
    "      d += timedelta(days = 7)\n",
    "\n",
    "listOfSaturdaysSundays = []\n",
    "for year in [2020,2021]:\n",
    "    for weekday in [5,6]:\n",
    "        for day in getDays(year, weekday):\n",
    "            listOfSaturdaysSundays.append(day)\n",
    "\n",
    "for e in listOfSaturdaysSundays:\n",
    "    holydayVacationTable.loc[datetime.datetime.combine(e, datetime.datetime.min.time())]=1\n",
    "\n",
    "holydayVacationTable.index = holydayVacationTable.index.rename(\"date\")\n",
    "\n",
    "if not os.path.exists('data/HolidayVacation'):\n",
    "    os.makedirs('data/HolidayVacation')    \n",
    "holydayVacationTable.to_csv('data/HolidayVacation/HolidayVacation.csv')\n",
    "print(\"Holyday/Vacation data computed (%s seconds)\" % (time.time() - start)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECDC data downloaded (2.8525516986846924 seconds)\n"
     ]
    }
   ],
   "source": [
    "# subnational data for bordering countries (only weekly) \n",
    "start = time.time()\n",
    "df = pd.read_csv('https://opendata.ecdc.europa.eu/covid19/subnationalcaseweekly/csv')\n",
    "if not os.path.exists('data/ECDC'):\n",
    "    os.makedirs('data/ECDC')\n",
    "df.to_csv('data/ECDC/ECDCsubnationalcaseweekly.csv')\n",
    "print(\"ECDC data downloaded (%s seconds)\" % (time.time() - start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Canton AG Time', 'Canton AG Masks mandatory in schools',\n",
       "       'Canton AG Upper secondary school, vocational schools and higher education',\n",
       "       'Canton AG Gatherings/private events', 'Canton AG Shops/Markets'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton AI Time', 'Canton AI Mountain railways'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton AR Time', 'Canton AR Mountain railways'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton BE Time', 'Canton BE Masks mandatory in schools',\n",
       "       'Canton BE Gatherings/private events', 'Canton BE Restaurants',\n",
       "       'Canton BE Discos/Nightclubs',\n",
       "       'Canton BE Mask mandatory in publicly accessible establishments/ spaces (shops etc.)',\n",
       "       'Canton BE Events', 'Canton BE Sport activities'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton BL Time', 'Canton BL Shops/Markets',\n",
       "       'Canton BL Sport/Wellness facilities',\n",
       "       'Canton BL Masks mandatory in schools'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton BS Time',\n",
       "       'Canton BS Mask mandatory in publicly accessible establishments/ spaces (shops etc.)',\n",
       "       'Canton BS Restaurants', 'Canton BS Masks mandatory in schools',\n",
       "       'Canton BS Sport/Wellness facilities',\n",
       "       'Canton BS Cultural, entertainment and recreational facilities'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton FR Time', 'Canton FR Demonstrations',\n",
       "       'Canton FR Cultural, entertainment and recreational facilities',\n",
       "       'Canton FR Sport/Wellness facilities', 'Canton FR Restaurants',\n",
       "       'Canton FR Masks mandatory in schools', 'Canton FR Singing allowed'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton GE Time', 'Canton GE Restaurants',\n",
       "       'Canton GE Cultural, entertainment and recreational facilities',\n",
       "       'Canton GE Sport/Wellness facilities', 'Canton GE Shops/Markets',\n",
       "       'Canton GE Gatherings/private events',\n",
       "       'Canton GE Masks mandatory in schools'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton GL Time', 'Canton GL Masks mandatory in schools',\n",
       "       'Canton GL Mountain railways', 'Canton GL Homeworking'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton GR Time', 'Canton GR Restaurants',\n",
       "       'Canton GR Cultural, entertainment and recreational facilities',\n",
       "       'Canton GR Sport/Wellness facilities'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton JU Time', 'Canton JU Gatherings/private events',\n",
       "       'Canton JU Demonstrations', 'Canton JU Restaurants',\n",
       "       'Canton JU Masks mandatory in schools',\n",
       "       'Canton JU Cultural, entertainment and recreational facilities',\n",
       "       'Canton JU Sport/Wellness facilities'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton LU Time', 'Canton LU Masks mandatory in schools',\n",
       "       'Canton LU Masks mandatory at work',\n",
       "       'Canton LU Cultural, entertainment and recreational facilities',\n",
       "       'Canton LU Sport/Wellness facilities', 'Canton LU Mountain railways'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton NE Time', 'Canton NE Gatherings/private events',\n",
       "       'Canton NE Cultural, entertainment and recreational facilities',\n",
       "       'Canton NE Restaurants', 'Canton NE Religious services'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton NW Time', 'Canton NW Mountain railways',\n",
       "       'Canton NW Masks mandatory in schools'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton OW Time', 'Canton OW Mountain railways',\n",
       "       'Canton OW Restaurants'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton SG Time', 'Canton SG Masks mandatory in schools',\n",
       "       'Canton SG Mountain railways', 'Canton SG Homeworking'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton SH Time', 'Canton SH Masks mandatory in schools'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton SO Time', 'Canton SO Sport/Wellness facilities',\n",
       "       'Canton SO Cultural, entertainment and recreational facilities',\n",
       "       'Canton SO Homeworking', 'Canton SO Shops/Markets',\n",
       "       'Canton SO Mountain railways',\n",
       "       'Canton SO Upper secondary school, vocational schools and higher education',\n",
       "       'Canton SO Masks mandatory in schools'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton SZ Time', 'Canton SZ Masks mandatory in schools',\n",
       "       'Canton SZ Masks mandatory at work', 'Canton SZ Mountain railways'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton TG Time', 'Canton TG Restaurants',\n",
       "       'Canton TG Discos/Nightclubs'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton TI Time',\n",
       "       'Canton TI Cultural, entertainment and recreational facilities',\n",
       "       'Canton TI Discos/Nightclubs', 'Canton TI Sport/Wellness facilities',\n",
       "       'Canton TI Upper secondary school, vocational schools and higher education',\n",
       "       'Canton TI universities and other educational establishments ',\n",
       "       'Canton TI Gatherings/private events', 'Canton TI Shops/Markets',\n",
       "       'Canton TI Restaurants'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton UR Time', 'Canton UR Mountain railways'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton VD Time', 'Canton VD Restaurants',\n",
       "       'Canton VD Gatherings/private events',\n",
       "       'Canton VD Cultural, entertainment and recreational facilities',\n",
       "       'Canton VD Sport/Wellness facilities',\n",
       "       'Canton VD Masks mandatory at work'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton VS Time', 'Canton VS Gatherings/private events',\n",
       "       'Canton VS Masks mandatory at work', 'Canton VS Restaurants',\n",
       "       'Canton VS universities and other educational establishments ',\n",
       "       'Canton VS Cultural, entertainment and recreational facilities',\n",
       "       'Canton VS Sport activities'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton ZG Time', 'Canton ZG Mountain railways',\n",
       "       'Canton ZG Masks mandatory in schools'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Canton ZH Time',\n",
       "       'Canton ZH Mask mandatory in publicly accessible establishments/ spaces (shops etc.)',\n",
       "       'Canton ZH Restaurants', 'Canton ZH Discos/Nightclubs',\n",
       "       'Canton ZH Gatherings/private events',\n",
       "       'Canton ZH Masks mandatory in schools', 'Canton ZH Shops/Markets',\n",
       "       'Canton ZH Mountain railways'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "federal and cantonal measures computed (48.918516397476196 seconds)\n"
     ]
    }
   ],
   "source": [
    "# compute federal and cantonal measures\n",
    "start = time.time()\n",
    "#======================== construct the federal measures ================\n",
    "columnNames = pd.read_excel('static_data/measures/measures.xlsx', sheet_name = 'Federal').columns\n",
    "measures = pd.read_excel('static_data/measures/measures.xlsx', sheet_name = 'Federal', skiprows=6, names=columnNames)\n",
    "\n",
    "measures = measures.set_index('Time')\n",
    "\n",
    "for day in pd.date_range(start=datetime.datetime(2020, 1, 1), end=datetime.datetime(2021, 12, 31)):\n",
    "    if not day in measures.index:\n",
    "        measures.loc[day] = [float('NaN')] * len(measures.columns)\n",
    "\n",
    "measures = measures.sort_index()\n",
    "\n",
    "# propagate the update changes to all other days\n",
    "for j in measures.columns: #measure\n",
    "    dailyMeasureLevel = 0\n",
    "    for i in measures.index: #day\n",
    "        if math.isnan(measures.loc[i, j]):\n",
    "            measures.loc[i, j] = dailyMeasureLevel\n",
    "        else:\n",
    "            dailyMeasureLevel = measures.loc[i, j]\n",
    "\n",
    "if not os.path.exists('data/measures'):\n",
    "    os.makedirs('data/measures')\n",
    "measures.to_csv('data/measures/federal.csv')\n",
    "#======================== construct the cantonal measures ================\n",
    "for c in cantonKeys: \n",
    "    # copy the federal measures and use max function (with some exceptions)\n",
    "    cantMeasuresComplete = measures.copy()\n",
    "    cantMeasures = pd.read_excel('static_data/measures/measures.xlsx', sheet_name = c)\n",
    "    cantMeasures = cantMeasures.set_index('Time')\n",
    "\n",
    "    for day in pd.date_range(start=datetime.datetime(2020, 1, 1), end=datetime.datetime(2021, 12, 31)):\n",
    "        if not day in cantMeasures.index:\n",
    "            cantMeasures.loc[day] = [float('NaN')] * len(cantMeasures.columns)\n",
    "\n",
    "    cantMeasures = cantMeasures.sort_index()\n",
    "\n",
    "\n",
    "    for m in cantMeasures.columns:\n",
    "        dailyMeasureLevel = float('NaN')\n",
    "        for day in cantMeasures.index:\n",
    "            if not math.isnan(cantMeasures.loc[day,m]):\n",
    "                if cantMeasures.loc[day,m] != -1:\n",
    "                    dailyMeasureLevel = cantMeasures.loc[day,m]\n",
    "                else:\n",
    "                    cantMeasures.loc[day,m] = 0\n",
    "                    dailyMeasureLevel = float('NaN')\n",
    "            elif math.isnan(cantMeasures.loc[day,m]) and not math.isnan(dailyMeasureLevel):\n",
    "                cantMeasures.loc[day,m] = dailyMeasureLevel\n",
    "            else:\n",
    "                cantMeasures.loc[day,m] = 0\n",
    "\n",
    "    # from 22.12 until 9.1 cantonal measures are stronger than federal for restaurants, recreational, sport facilities\n",
    "    for m in cantMeasures.columns:\n",
    "        for day in cantMeasures.index:\n",
    "            if (day < datetime.datetime(2021, 1, 9) and day >= datetime.datetime(2020, 12, 22)  and (m == 'Restaurants' or m=='Cultural, entertainment and recreational facilities' or m=='Sport/Wellness facilities')) or (day >= datetime.datetime(2020, 12, 23) and day < datetime.datetime(2021, 1, 3) and m=='Gatherings/private events'):\n",
    "                # cantonal exeption possible\n",
    "                if cantMeasures.loc[day,m] != 0:\n",
    "                    cantMeasuresComplete.loc[day,m] = cantMeasures.loc[day,m]\n",
    "            else:\n",
    "                cantMeasuresComplete.loc[day,m] = max(cantMeasuresComplete.loc[day,m], cantMeasures.loc[day,m])\n",
    "    \n",
    "    if not os.path.exists('data/measures'):\n",
    "        os.makedirs('data/measures')\n",
    "    cantMeasuresComplete.to_csv('data/measures/'+c+'.csv')\n",
    "print(\"federal and cantonal measures computed (%s seconds)\" % (time.time() - start)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded historical statistical weather data(1621.4294505119324 seconds)\n"
     ]
    }
   ],
   "source": [
    "# download the historical statistical weather data from 1.1.2020 to 18.3.2020 (has only to run once)\n",
    "'''\n",
    "start = time.time()\n",
    "for cantonId in weatherDictionary.keys():\n",
    "    cityId = str(weatherDictionary[cantonId])\n",
    "    statisticalData = pd.DataFrame()\n",
    "    for everyDay in pd.date_range(start=datetime.datetime(2020, 1, 1), end=datetime.datetime(2020, 3, 18)):\n",
    "        monthNumber = str(everyDay.month)\n",
    "        dayNumber = str(everyDay.day)\n",
    "        apiCall =\"https://history.openweathermap.org/data/2.5/aggregated/day?id=\"+cityId+\"&month=\"+monthNumber+\"&day=\"+dayNumber+\"&appid=\"+apiKey\n",
    "        with urllib.request.urlopen(apiCall) as url:\n",
    "                    data = json.loads(url.read().decode())\n",
    "                    dfloaded = pd.json_normalize(data[\"result\"])\n",
    "                    statisticalData = statisticalData.append(dfloaded)\n",
    "    if not os.path.exists('static_data/statistical_historicweather'):\n",
    "        os.makedirs('static_data/statistical_historicweather')\n",
    "    statisticalData.to_csv(\"static_data/statistical_historicweather/statistical_\"+ cantonId +\".csv\")\n",
    "print(\"downloaded historical statistical weather data(%s seconds)\" % (time.time() - start)) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT run this code again, this code ran on 18.3.2021 and the data was manually moved to a special folder\n",
    "'''\n",
    "for cantonId in weatherDictionary.keys():\n",
    "    cityId = str(weatherDictionary[cantonId])\n",
    "\n",
    "    # create new data frame for each canton\n",
    "    weather = pd.DataFrame(columns=['dt', 'weather', 'main.temp', 'main.feels_like', 'main.pressure',\n",
    "           'main.humidity', 'main.temp_min', 'main.temp_max', 'wind.speed',\n",
    "           'wind.deg', 'clouds.all', 'rain.1h'])\n",
    "\n",
    "    # can only get one week for one call\n",
    "    startDate = datetime.datetime(2020, 3, 19)\n",
    "    endDate = datetime.datetime.today()\n",
    "    for week in pd.date_range(start=startDate, end=endDate, freq='W-THU'):\n",
    "        unixTimeUTCstart = int(week.replace(tzinfo=timezone.utc).timestamp())\n",
    "        unixTimeUTCend = int(endDate.replace(tzinfo=timezone.utc).timestamp())\n",
    "        apiCall = \"http://history.openweathermap.org/data/2.5/history/city?id=\"+cityId+\"&type=hour&start=\"+str(unixTimeUTCstart)+\"&end=\"+str(unixTimeUTCend)+\"&appid=\"+apiKey\n",
    "        with urllib.request.urlopen(apiCall) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            dfloaded = pd.json_normalize(data[\"list\"])\n",
    "            weather = weather.append(dfloaded, ignore_index=True)\n",
    "\n",
    "    # remove some duplicates (first entry overlaps)\n",
    "    weather.drop_duplicates(subset=['dt'])\n",
    "    # transform unix time to datetime\n",
    "    weather[\"dt\"] = weather[\"dt\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    if not os.path.exists('static_data/historicweather'):\n",
    "        os.makedirs('static_data/historicweather')\n",
    "    weather.to_csv(\"static_data/historicweather/\"+ cantonId +\".csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historic weather update (load recently historic weather data) (from 4.2.21 because of weekly fetches)\n",
    "for cantonId in weatherDictionary.keys():\n",
    "    cityId = str(weatherDictionary[cantonId])\n",
    "\n",
    "    # create new data frame for each canton\n",
    "    weather = pd.DataFrame(columns=['dt', 'weather', 'main.temp', 'main.feels_like', 'main.pressure',\n",
    "           'main.humidity', 'main.temp_min', 'main.temp_max', 'wind.speed',\n",
    "           'wind.deg', 'clouds.all', 'rain.1h'])\n",
    "\n",
    "    # can only get one week for one call\n",
    "    startDate = datetime.datetime(2021, 2, 1)\n",
    "    endDate = datetime.datetime.today()\n",
    "    for week in pd.date_range(start=startDate, end=endDate, freq='W-THU'):\n",
    "        unixTimeUTCstart = int(week.replace(tzinfo=timezone.utc).timestamp())\n",
    "        unixTimeUTCend = int(endDate.replace(tzinfo=timezone.utc).timestamp())\n",
    "        apiCall = \"http://history.openweathermap.org/data/2.5/history/city?id=\"+cityId+\"&type=hour&start=\"+str(unixTimeUTCstart)+\"&end=\"+str(unixTimeUTCend)+\"&appid=\"+apiKey\n",
    "        with urllib.request.urlopen(apiCall) as url:\n",
    "            data = json.loads(url.read().decode())\n",
    "            dfloaded = pd.json_normalize(data[\"list\"])\n",
    "            weather = weather.append(dfloaded, ignore_index=True)\n",
    "\n",
    "    # remove some duplicates (first entry overlaps)\n",
    "    weather.drop_duplicates(subset=['dt'])\n",
    "    # transform unix time to datetime\n",
    "    weather[\"dt\"] = weather[\"dt\"].apply(lambda x: datetime.datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    if not os.path.exists('data/historicweatherupdate'):\n",
    "        os.makedirs('data/historicweatherupdate')\n",
    "    weather.to_csv(\"data/historicweatherupdate/\"+ cantonId +\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'backups/backup-2021-04-06-15-50-46'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a backup of the data we just loaded\n",
    "if not os.path.exists('backups'):\n",
    "    os.makedirs('backups')\n",
    "now = datetime.datetime.now()\n",
    "backupname = now.strftime(\"backup-%Y-%m-%d-%H-%M-%S\")\n",
    "shutil.copytree('data', 'backups/'+backupname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  \\n# Oxford COVID-19 Government Response Tracker\\ndf = pd.read_csv('https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv')\\nif not os.path.exists('data/Oxford'):\\n    os.makedirs('data/Oxford')\\ndf.to_csv('data/Oxford/OxfordStrigencyIndex.csv')\\n\\n# International data for bordering countries (only country level data)\\ndf = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\\nif not os.path.exists('data/OWID'):\\n    os.makedirs('data/OWID')\\ndf.to_csv('data/OWID/OWIDcoviddata.csv')\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unused data\n",
    "'''  \n",
    "# Oxford COVID-19 Government Response Tracker\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv')\n",
    "if not os.path.exists('data/Oxford'):\n",
    "    os.makedirs('data/Oxford')\n",
    "df.to_csv('data/Oxford/OxfordStrigencyIndex.csv')\n",
    "\n",
    "# International data for bordering countries (only country level data)\n",
    "df = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n",
    "if not os.path.exists('data/OWID'):\n",
    "    os.makedirs('data/OWID')\n",
    "df.to_csv('data/OWID/OWIDcoviddata.csv')\n",
    "\n",
    "# gets the 16 day weather forecast\n",
    "for cantonId in weatherDictionary.keys():\n",
    "    cityId = str(weatherDictionary[cantonId])\n",
    "    forecastData = pd.DataFrame()\n",
    "    apiCall = \"https://api.openweathermap.org/data/2.5/forecast/daily?id=\"+cityId+\"&cnt=16&appid=\"+apiKey\n",
    "    with urllib.request.urlopen(apiCall) as url:\n",
    "        data = json.loads(url.read().decode())\n",
    "        forecastData = pd.json_normalize(data[\"list\"])\n",
    "\n",
    "    if not os.path.exists('data/weatherforecast'):\n",
    "        os.makedirs('data/weatherforecast')\n",
    "    forecastData.to_csv(\"data/weatherforecast/\"+ cantonId +\".csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

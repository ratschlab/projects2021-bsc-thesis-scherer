{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "familiar-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "from joblib import dump, load\n",
    "from datetime import timedelta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import lightgbm as lightgbm\n",
    "\n",
    "# settings:\n",
    "numberOfInputWeeks = 3 # must be equal to the number of input weeks set in data preperator\n",
    "numberOfOutputWeeks = 4 # must be equal to the number of output week set in data preperator\n",
    "\n",
    "\n",
    "\n",
    "# data preperation\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "data = pd.read_csv(\"completedata.csv\")\n",
    "\n",
    "\n",
    "outputCategories = ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]\n",
    "numberOfOutputs = len(outputCategories)\n",
    "\n",
    "split = numberOfOutputs * numberOfOutputWeeks + 2\n",
    "train_features = data[data['category']=='train'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "train_labels = data[data['category']=='train'].iloc[:,-split:-2]\n",
    "\n",
    "validation1_features = data[data['category']=='validation 1'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation1_labels = data[data['category']=='validation 1'].iloc[:,-split:-2]\n",
    "validation2_features = data[data['category']=='validation 2'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation2_labels = data[data['category']=='validation 2'].iloc[:,-split:-2]\n",
    "validation1And2_labels = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,-split:-2]\n",
    "validation1And2_features = data[(data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "\n",
    "pip = Pipeline([('minmax_scaler', MinMaxScaler())])\n",
    "X_train = pip.fit_transform(train_features[train_features.columns].values)\n",
    "X_valid1 = pip.transform(validation1_features[train_features.columns].values)\n",
    "X_valid2 = pip.transform(validation2_features[train_features.columns].values)\n",
    "X_valid1And2 = pip.transform(validation1And2_features[train_features.columns].values)\n",
    "\n",
    "\n",
    "def generic1(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "def generic2(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic3(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic4(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic5(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic6(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic7(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic8(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[7], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "def genericKerasModel(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput):\n",
    "    if len(hiddenLayers) == 1:\n",
    "        return generic1(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 2:\n",
    "        return generic2(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 3:\n",
    "        return generic3(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 4:\n",
    "        return generic4(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 5:\n",
    "        return generic5(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 6:\n",
    "        return generic6(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 7:\n",
    "        return generic7(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    else:\n",
    "        return generic8(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serial-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Keras: 597\n",
      "Keras: 19584\n",
      "Total: 20181\n",
      "INFO:tensorflow:Assets written to: models/597_case_inz_entries_7dayAverage/assets\n",
      "INFO:tensorflow:Assets written to: models/597_hosp_inz_entries_7dayAverage/assets\n",
      "INFO:tensorflow:Assets written to: models/597_death_inz_entries_7dayAverage/assets\n",
      "INFO:tensorflow:Assets written to: models/597_testPositvity_7dayAverage/assets\n",
      "INFO:tensorflow:Assets written to: models/597_transit_stations_percent_change_from_baseline_7dayAverage/assets\n",
      "INFO:tensorflow:Assets written to: models/597_workplaces_percent_change_from_baseline_7dayAverage/assets\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "numberOfEstimators = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,0,1,10, 100]:\n",
    "    for isMultiWeek in [True,False]:\n",
    "         estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"Ridge\",\n",
    "                  \"isMultiWeek\": isMultiWeek,\n",
    "                  \"alpha\": alpha\n",
    "                })          \n",
    "#print(\"Ridge: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,0,1,10, 100]:\n",
    "    for isMultiWeek in [True,False]:\n",
    "         estimators.append(\n",
    "                {\n",
    "                  \"modelClass\": \"Lasso\",\n",
    "                  \"isMultiWeek\": isMultiWeek,\n",
    "                  \"alpha\": alpha\n",
    "                })\n",
    "#print(\"Lasso: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)             \n",
    "             \n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,0,1,10, 100]: \n",
    "    for isMultiWeek in [True,False]:\n",
    "        for kernel in ['linear','poly','polynomial','rbf','laplacian','sigmoid','cosine']:\n",
    "            estimators.append(\n",
    "            {\n",
    "              \"modelClass\": \"KernelRidge\",\n",
    "              \"isMultiWeek\": isMultiWeek,\n",
    "              \"alpha\": alpha,\n",
    "              \"kernel\": kernel\n",
    "            })\n",
    "#print(\"KernelRidge: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,0,1,10, 100]:\n",
    "    estimators.append(\n",
    "            {\n",
    "              \"modelClass\": \"MultiTaskLasso\",\n",
    "              \"isMultiWeek\": True,\n",
    "              \"alpha\": alpha\n",
    "            })\n",
    "#print(\"MultiTaskLasso: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "      \n",
    "\n",
    "for alpha in [0.01,0.1,0,1,10]:\n",
    "    for lamb in [0.01,0.1,0,1,10]:\n",
    "            for n_estimators in [100,500,1000]:\n",
    "                estimators.append(\n",
    "                        {\n",
    "                            \"modelClass\": \"LGBM\",\n",
    "                            \"isMultiWeek\": False,\n",
    "                            \"n_estimators\": n_estimators,\n",
    "                            \"alpha\": alpha,\n",
    "                            \"lambda\": lamb\n",
    "                        }\n",
    "                    )\n",
    "#print(\"LGBM: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "for alpha in [0.01,0.1,0,1,10]:\n",
    "    for lamb in [0.01,0.1,0,1,10]:\n",
    "            for n_estimators in [100,500,1000]:\n",
    "                estimators.append(\n",
    "                        {\n",
    "                            \"modelClass\": \"XGB\",\n",
    "                            \"isMultiWeek\": False,\n",
    "                            \"n_estimators\": n_estimators,\n",
    "                            \"alpha\": alpha,\n",
    "                            \"lambda\": lamb\n",
    "                        }\n",
    "                    )\n",
    "#print(\"XGB: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "            \n",
    "for C in [0.001,0.01,0.1,1,10,100]:\n",
    "    estimators.append(\n",
    "                        {\n",
    "                            \"modelClass\": \"SVR\",\n",
    "                            \"isMultiWeek\": False,\n",
    "                            \"C\": C\n",
    "                        }\n",
    "                    )\n",
    "#print(\"SVR: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "\n",
    "for alpha in [0.001, 0.01,0.1, 1, 10, 100]:\n",
    "    for learning_rate in ['invscaling','adaptive','optimal']:\n",
    "        for penalty in ['l1','l2','elasticnet']:\n",
    "            estimators.append(\n",
    "                {\n",
    "                    \"modelClass\": \"SGD\",\n",
    "                    \"isMultiWeek\": False ,\n",
    "                    \"alpha\": alpha,\n",
    "                    \"learning_rate\": learning_rate,\n",
    "                    \"penalty\": penalty  \n",
    "                }\n",
    "            )\n",
    "#print(\"SGD: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "                    \n",
    "for max_features in [\"auto\",10,100,200]:\n",
    "    for min_samples_split in [2,3,4]:\n",
    "        for min_samples_leaf in [1,2,3]:\n",
    "            for n_estimators in [100,500,1000]:\n",
    "                for isMultiWeek in [True,False]:\n",
    "                    estimators.append(\n",
    "                        {\n",
    "                            \"modelClass\": \"RandomForrest\",\n",
    "                            \"isMultiWeek\": isMultiWeek,\n",
    "                            \"n_estimators\": n_estimators,\n",
    "                            \"max_features\": max_features,\n",
    "                            \"min_samples_split\": min_samples_split,\n",
    "                            \"min_samples_leaf\": min_samples_leaf\n",
    "                        }\n",
    "                    )\n",
    "#print(\"RandomForrest: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "\n",
    "print(\"Start Keras: \"+str(len(estimators)))\n",
    "\n",
    "# adding keras model construction parameters\n",
    "for learningRate in [0.001,0.0001]: \n",
    "    for dropoutValue in [0,0.2,0.3,0.5]: \n",
    "        for l1reg in [0.0001, 0.001, 0.01,0.1, 1, 0]:\n",
    "            for alpha in [0.0001, 0.001, 0.01,0.1, 1, 0]:\n",
    "                for hiddenLayers in [[20],\n",
    "                                     [30],\n",
    "                                     [40],\n",
    "                                     [50],\n",
    "                                     [60],\n",
    "                                     [70],\n",
    "                                     [80],\n",
    "                                     [90],\n",
    "                                     [100],\n",
    "                                     [125],\n",
    "                                     [150],\n",
    "                                     [175],\n",
    "                                     [200],\n",
    "                                     [225],\n",
    "                                     [250],\n",
    "                                     [300],\n",
    "                                     [350],\n",
    "                                     [400],\n",
    "                                     [500],\n",
    "                                     [1000],\n",
    "                                     [100,100],\n",
    "                                     [125,125],\n",
    "                                     [175,175],\n",
    "                                     [200,200],\n",
    "                                     [225,225],\n",
    "                                     [250,250],\n",
    "                                     [350,350],\n",
    "                                     [400,400],\n",
    "                                     [500,500],\n",
    "                                     [1000,1000],\n",
    "                                     [30,15],\n",
    "                                     [30,20],\n",
    "                                     [40,20],\n",
    "                                     [60,30],\n",
    "                                     [70,35],\n",
    "                                     [80,40],\n",
    "                                     [90,45],\n",
    "                                     [100, 50],\n",
    "                                     [125,63],\n",
    "                                     [175,87],\n",
    "                                     [200,100],\n",
    "                                     [225,112],\n",
    "                                     [250,125],\n",
    "                                     [350,175],\n",
    "                                     [400,200],\n",
    "                                     [500,250],\n",
    "                                     [1000,500],\n",
    "                                     [100, 50, 25],\n",
    "                                     [100, 50, 50],\n",
    "                                     [125,63, 30],\n",
    "                                     [175,87,40],\n",
    "                                     [200, 100, 50],\n",
    "                                     [225,112, 56],\n",
    "                                     [250,125, 62],\n",
    "                                     [350,175, 85],\n",
    "                                     [300,150,75],\n",
    "                                     [400,200, 100],\n",
    "                                     [250,100, 20],\n",
    "                                     [400,200, 50],\n",
    "                                     [400,100, 50],\n",
    "                                     [500,250, 125],\n",
    "                                     [1000,500, 250],\n",
    "                                     [400, 200, 100, 90, 80, 70, 60, 50],\n",
    "                                     [500, 250, 120, 100, 90, 80, 70, 60],\n",
    "                                     [400, 300, 150, 120, 100, 70, 50, 30],\n",
    "                                     [400, 100, 50, 50, 50, 50, 50, 50],\n",
    "                                     [400, 200, 100, 50, 50, 50, 50, 50],\n",
    "                                     [200, 150, 100, 50, 50, 50, 50, 50]\n",
    "                               ]:\n",
    "                    estimators.append(\n",
    "                        {\n",
    "                          \"modelClass\": \"Keras\",\n",
    "                          \"isMultiWeek\": True,\n",
    "                          \"hiddenLayers\": hiddenLayers,\n",
    "                          \"numberOfhiddenLayers\": len(hiddenLayers),\n",
    "                          \"isTwoWay\": False,\n",
    "                          \"l1reg\": l1reg,\n",
    "                          \"alpha\": alpha,\n",
    "                          \"dropoutValue\": dropoutValue,\n",
    "                          \"learningRate\": learningRate\n",
    "                        }\n",
    "                    )\n",
    "print(\"Keras: \"+str(len(estimators)-numberOfEstimators))\n",
    "numberOfEstimators = len(estimators)\n",
    "\n",
    "                    \n",
    "print(\"Total: \"+str(len(estimators)))\n",
    "             \n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"estimatorId\", help=\"computes estimator with given id\",type=int)\n",
    "args = parser.parse_args()\n",
    "estimatorId = args.estimatorId\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "estimators.append({\"modelClass\": \"Ridge\",\"alpha\": 10,\"isMultiWeek\": True})\n",
    "estimators.append({\"modelClass\": \"Ridge\",\"alpha\": 10,\"isMultiWeek\": False})\n",
    "estimators.append({\"modelClass\": \"Lasso\",\"alpha\": 10,\"isMultiWeek\": True})\n",
    "estimators.append({\"modelClass\": \"Lasso\",\"alpha\": 10,\"isMultiWeek\": False})\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"Keras\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"hiddenLayers\": [10,10],\n",
    "                      \"numberOfhiddenLayers\": 2,\n",
    "                      \"isTwoWay\": True,\n",
    "                      \"l1reg\": 0.001,\n",
    "                      \"alpha\": 0.01,\n",
    "                      \"dropoutValue\": 0.3,\n",
    "                      \"learningRate\": 0.0001\n",
    "                  }\n",
    "                )\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"Keras\",\n",
    "                      \"isMultiWeek\": False,\n",
    "                      \"hiddenLayers\": [10],\n",
    "                      \"numberOfhiddenLayers\": 2,\n",
    "                      \"isTwoWay\": True,\n",
    "                      \"l1reg\": 0.001,\n",
    "                      \"alpha\": 0.01,\n",
    "                      \"dropoutValue\": 0.3,\n",
    "                      \"learningRate\": 0.0001\n",
    "                  }\n",
    "                )\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"SGD\",\n",
    "                        \"alpha\": 10,\n",
    "                        \"learning_rate\": 'invscaling',\n",
    "                        \"penalty\": 'l2',\n",
    "                        \"isMultiWeek\": False    \n",
    "                    }\n",
    "                )\n",
    "estimators.append(\n",
    "            {\n",
    "              \"modelClass\": \"MultiTaskLasso\",\n",
    "              \"alpha\": 10,\n",
    "              \"isMultiWeek\": True\n",
    "            })\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"SVR\",\n",
    "                        \"C\": 10,\n",
    "                        \"isMultiWeek\": False\n",
    "                    }\n",
    "                )\n",
    "\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"RandomForrest\",\n",
    "                        \"n_estimators\": 10,\n",
    "                        \"max_features\": None,\n",
    "                        \"min_samples_split\": 2,\n",
    "                        \"min_samples_leaf\": 1,\n",
    "                        \"isMultiWeek\": True\n",
    "                    }\n",
    "                 )\n",
    "\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"RandomForrest\",\n",
    "                        \"n_estimators\": 10,\n",
    "                        \"max_features\": 100,\n",
    "                        \"min_samples_split\": 2,\n",
    "                        \"min_samples_leaf\": 1,\n",
    "                        \"isMultiWeek\": False\n",
    "                    }\n",
    "                 )\n",
    "\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"XGB\",\n",
    "                        \"n_estimators\": 10,\n",
    "                        \"alpha\": 0.001,\n",
    "                        \"lambda\": 0.01,\n",
    "                        \"isMultiWeek\": False\n",
    "                    }\n",
    "                 )\n",
    "estimators.append(\n",
    "                    {\n",
    "                        \"modelClass\": \"LGBM\",\n",
    "                        \"n_estimators\": 10,\n",
    "                        \"alpha\": 0.001,\n",
    "                        \"lambda\": 0.01,\n",
    "                        \"isMultiWeek\": False\n",
    "                    }\n",
    "                )\n",
    "\n",
    "estimators.append(\n",
    "            {\n",
    "              \"modelClass\": \"KernelRidge\",\n",
    "              \"alpha\": 10,\n",
    "              \"kernel\": \"linear\",\n",
    "              \"isMultiWeek\": True\n",
    "            })\n",
    "\n",
    "estimators.append(\n",
    "            {\n",
    "              \"modelClass\": \"KernelRidge\",\n",
    "              \"alpha\": 10,\n",
    "              \"kernel\": \"linear\",\n",
    "              \"isMultiWeek\": False\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "estimatorId = 597\n",
    "'''    \n",
    "\n",
    "# constructs and saves the results of a fitted estimator    \n",
    "def constructResults(estimator, task, weekNumber, numberOfRanEpochs):\n",
    "    if weekNumber == -1: # we make predictions for all weeks\n",
    "        # predictions for all weeks\n",
    "        predictions1 = pd.DataFrame(estimator.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]) \n",
    "        predictions2 = pd.DataFrame(estimator.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)])\n",
    "        \n",
    "        # validation for all weeks\n",
    "        y_valid1 = validation1_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "        y_valid2 = validation2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "        \n",
    "        resultsDf = pd.DataFrame()\n",
    "        # compute and safe results for every week\n",
    "        for outputWeekNumber in range(0,numberOfOutputWeeks):\n",
    "            # compute root mean squared error for validation sets\n",
    "            rmse1 = np.sqrt(mean_squared_error(predictions1[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid1[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "            rmse2 = np.sqrt(mean_squared_error(predictions2[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_valid2[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "            # safe the results and all model parameters\n",
    "            res = {}\n",
    "            if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"hiddenLayers\":[estimators[estimatorId][\"hiddenLayers\"]],\n",
    "                     \"numberOfhiddenLayers\":[len(estimators[estimatorId][\"hiddenLayers\"])],\n",
    "                     \"isTwoWay\": [estimators[estimatorId][\"isTwoWay\"]],\n",
    "                     \"l1reg\": [estimators[estimatorId][\"l1reg\"]],\n",
    "                     \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                     \"dropoutValue\":[estimators[estimatorId][\"dropoutValue\"]],\n",
    "                     \"learningRate\":[estimators[estimatorId][\"learningRate\"]],\n",
    "                     \"numberOfRanEpochs\": [numberOfRanEpochs]\n",
    "                    }\n",
    "                \n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                     \"max_features\": [estimators[estimatorId][\"max_features\"]],\n",
    "                     \"min_samples_split\": [estimators[estimatorId][\"min_samples_split\"]],\n",
    "                     \"min_samples_leaf\": [estimators[estimatorId][\"min_samples_leaf\"]]\n",
    "                    }               \n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"KernelRidge\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                     \"kernel\": [estimators[estimatorId][\"kernel\"]],\n",
    "                    }\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"alpha\": [estimators[estimatorId][\"alpha\"]]\n",
    "                    }\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"alpha\": [estimators[estimatorId][\"alpha\"]]\n",
    "                    }\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "                res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                     'task':[task],\n",
    "                     'week':[outputWeekNumber], \n",
    "                     'model rmse 1':[rmse1], \n",
    "                     'model rmse 2':[rmse2],\n",
    "                     'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                     \"alpha\": [estimators[estimatorId][\"alpha\"]]\n",
    "                    }\n",
    "            else:\n",
    "                raise ValueError('Tried to save results for an unsupported estimator')\n",
    "            resultsDf = resultsDf.append(pd.DataFrame(data=res), ignore_index = True)\n",
    "        return resultsDf\n",
    "    else: # we make predictions only for one week\n",
    "        # predictions for one week\n",
    "        predictions1 = pd.DataFrame(estimator.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(weekNumber)]) \n",
    "        predictions2 = pd.DataFrame(estimator.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(weekNumber)])\n",
    "        \n",
    "        # validation for one week\n",
    "        y_valid1 = validation1_labels[[\"output_\"+task+\"_\"+str(weekNumber)]]\n",
    "        y_valid2 = validation2_labels[[\"output_\"+task+\"_\"+str(weekNumber)]]\n",
    "        \n",
    "        rmse1 = np.sqrt(mean_squared_error(predictions1[\"pred_week_\"+task+\"_\"+str(weekNumber)], y_valid1[\"output_\"+task+\"_\"+str(weekNumber)]))\n",
    "        rmse2 = np.sqrt(mean_squared_error(predictions2[\"pred_week_\"+task+\"_\"+str(weekNumber)], y_valid2[\"output_\"+task+\"_\"+str(weekNumber)]))\n",
    "        # safe the results and all model parameters\n",
    "        res = {}\n",
    "        if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"hiddenLayers\":[estimators[estimatorId][\"hiddenLayers\"]],\n",
    "                 \"numberOfhiddenLayers\":[len(estimators[estimatorId][\"hiddenLayers\"])],\n",
    "                 \"isTwoWay\": [estimators[estimatorId][\"isTwoWay\"]],\n",
    "                 \"l1reg\": [estimators[estimatorId][\"l1reg\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"dropoutValue\":[estimators[estimatorId][\"dropoutValue\"]],\n",
    "                 \"learningRate\":[estimators[estimatorId][\"learningRate\"]],\n",
    "                 \"numberOfRanEpochs\": [numberOfRanEpochs]\n",
    "                }\n",
    "\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"max_features\": [estimators[estimatorId][\"max_features\"]],\n",
    "                 \"min_samples_split\": [estimators[estimatorId][\"min_samples_split\"]],\n",
    "                 \"min_samples_leaf\": [estimators[estimatorId][\"min_samples_leaf\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"XGB\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"lambda\": [estimators[estimatorId][\"lambda\"]]\n",
    "                } \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"LGBM\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"lambda\": [estimators[estimatorId][\"lambda\"]]\n",
    "                } \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"KernelRidge\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"kernel\": [estimators[estimatorId][\"kernel\"]],\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"SGD\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"learning_rate\": [estimators[estimatorId][\"learning_rate\"]],\n",
    "                 \"penalty\": [estimators[estimatorId][\"penalty\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"SVR\":\n",
    "            res = {'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[weekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"C\": [estimators[estimatorId][\"C\"]]\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError('Tried to save results for an unsupported estimator')\n",
    "        return pd.DataFrame(data=res)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "# training\n",
    "\n",
    "if estimators[estimatorId][\"isMultiWeek\"]:\n",
    "    # we just train one model per task\n",
    "    for task in outputCategories:\n",
    "        # get train labels for all weeks\n",
    "        y_train = train_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values\n",
    "        if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "            # get validation labels for all weeks (used for early stopping)\n",
    "            y_valid1And2 = validation1And2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values \n",
    "            # construct Keras model\n",
    "            estimator = genericKerasModel(\n",
    "                estimators[estimatorId][\"learningRate\"],\n",
    "                estimators[estimatorId][\"hiddenLayers\"],\n",
    "                estimators[estimatorId][\"dropoutValue\"],\n",
    "                estimators[estimatorId][\"l1reg\"],\n",
    "                estimators[estimatorId][\"alpha\"],\n",
    "                estimators[estimatorId][\"isMultiWeek\"]\n",
    "            )\n",
    "            # fit Keras model\n",
    "            history = estimator.fit(X_train, \n",
    "                                  y_train, \n",
    "                                  batch_size=32, \n",
    "                                  epochs=1000, \n",
    "                                  verbose=0, \n",
    "                                  validation_data=(X_valid1And2,y_valid1And2), \n",
    "                                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "            if not os.path.exists('models/'):\n",
    "                os.makedirs('models')\n",
    "            estimator.save(\"models/\"+str(estimatorId)+\"_\"+task)\n",
    "            numberOfRanEpochs = len(history.history['loss'])\n",
    "            results = results.append(constructResults(estimator, task, -1, numberOfRanEpochs), ignore_index = True)\n",
    "            \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "            estimator = RandomForestRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                              max_features=estimators[estimatorId][\"max_features\"],\n",
    "                                              min_samples_split=estimators[estimatorId][\"min_samples_split\"],\n",
    "                                              min_samples_leaf=estimators[estimatorId][\"min_samples_leaf\"],\n",
    "                                              n_jobs=-1\n",
    "                                             )\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"KernelRidge\":\n",
    "            estimator = KernelRidge(alpha=estimators[estimatorId][\"alpha\"], \n",
    "                                    kernel=estimators[estimatorId][\"kernel\"],\n",
    "                                    )\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "            estimator = linear_model.Ridge(alpha=estimators[estimatorId][\"alpha\"])\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "            estimator = linear_model.Lasso(alpha=estimators[estimatorId][\"alpha\"])\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"SGD\":\n",
    "            estimator = linear_model.SGDRegressor(learning_rate = estimators[estimatorId][\"learning_rate\"],\n",
    "                                                  penalty=estimators[estimatorId][\"penalty\"],\n",
    "                                                  alpha=estimators[estimatorId][\"alpha\"],\n",
    "                                                  max_iter=10000, \n",
    "                                                  tol=0.00001, \n",
    "                                                  n_iter_no_change=10)\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "            estimator = linear_model.MultiTaskLasso(alpha = estimators[estimatorId][\"alpha\"])\n",
    "            estimator.fit(X_train,y_train)\n",
    "            results = results.append(constructResults(estimator, task, -1, -1), ignore_index = True)\n",
    "        else:\n",
    "            raise ValueError('Tried to fit an unsupported estimator')            \n",
    "else:\n",
    "    # we have to train one model per output week and per task\n",
    "    for outputWeekNumber in range(0,numberOfOutputWeeks):\n",
    "        for task in ['transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage']:\n",
    "            # get train labels for one week\n",
    "            y_train = train_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber)]].values\n",
    "            if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "                # get validation labels for one week (used for early stopping)\n",
    "                y_valid = validation1And2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber)]].values \n",
    "                # construct Keras model\n",
    "                estimator = genericKerasModel(\n",
    "                    estimators[estimatorId][\"learningRate\"],\n",
    "                    estimators[estimatorId][\"hiddenLayers\"],\n",
    "                    estimators[estimatorId][\"dropoutValue\"],\n",
    "                    estimators[estimatorId][\"l1reg\"],\n",
    "                    estimators[estimatorId][\"alpha\"],\n",
    "                    estimators[estimatorId][\"isMultiWeek\"]\n",
    "                )\n",
    "                # fit Keras model\n",
    "                history = estimator.fit(X_train, \n",
    "                  y_train, \n",
    "                  batch_size=32, \n",
    "                  epochs=1000, \n",
    "                  verbose=0, \n",
    "                  validation_data=(X_valid1And2,y_valid), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "                numberOfRanEpochs = len(history.history['loss'])\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, numberOfRanEpochs), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "                estimator = RandomForestRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                              max_features=estimators[estimatorId][\"max_features\"],\n",
    "                                              min_samples_split=estimators[estimatorId][\"min_samples_split\"],\n",
    "                                              min_samples_leaf=estimators[estimatorId][\"min_samples_leaf\"],\n",
    "                                              n_jobs=-1\n",
    "                                             )\n",
    "                estimator.fit(X_train,y_train.ravel())\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"KernelRidge\":\n",
    "                estimator = KernelRidge(alpha=estimators[estimatorId][\"alpha\"], \n",
    "                                    kernel=estimators[estimatorId][\"kernel\"],\n",
    "                                    )\n",
    "                estimator.fit(X_train,y_train)\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"Ridge\":\n",
    "                estimator = linear_model.Ridge(alpha=estimators[estimatorId][\"alpha\"])\n",
    "                estimator.fit(X_train,y_train)\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "                estimator = linear_model.Lasso(alpha=estimators[estimatorId][\"alpha\"])\n",
    "                estimator.fit(X_train,y_train)\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"LGBM\":\n",
    "                estimator = lightgbm.LGBMRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                                   reg_alpha=estimators[estimatorId][\"alpha\"], \n",
    "                                                   reg_lambda=estimators[estimatorId][\"lambda\"], \n",
    "                                                   n_jobs=-1)\n",
    "                estimator.fit(X_train,y_train.ravel())\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"XGB\":\n",
    "                estimator = xgb.XGBRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                             reg_alpha=estimators[estimatorId][\"alpha\"], \n",
    "                                             reg_lambda=estimators[estimatorId][\"lambda\"], \n",
    "                                             n_jobs=-1)\n",
    "                estimator.fit(X_train,y_train.ravel())\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"SGD\":\n",
    "                estimator = linear_model.SGDRegressor(learning_rate = estimators[estimatorId][\"learning_rate\"],\n",
    "                                                  penalty=estimators[estimatorId][\"penalty\"],\n",
    "                                                  alpha=estimators[estimatorId][\"alpha\"],\n",
    "                                                  max_iter=10000, \n",
    "                                                  tol=0.00001, \n",
    "                                                  n_iter_no_change=10)\n",
    "                estimator.fit(X_train,y_train.ravel())\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            elif estimators[estimatorId][\"modelClass\"] == \"SVR\":\n",
    "                estimator = svm.SVR(C=estimators[estimatorId][\"C\"])\n",
    "                estimator.fit(X_train,y_train.ravel())\n",
    "                results = results.append(constructResults(estimator, task, outputWeekNumber, -1), ignore_index = True)\n",
    "            else:\n",
    "                raise ValueError('Tried to fit an unsupported estimator')\n",
    "\n",
    "def generateModelId(dictionary):\n",
    "    modelId = \"\"\n",
    "    for key in dictionary.keys():\n",
    "        modelId = modelId + key +\"=\"+ str(dictionary[key]) +\"/\"\n",
    "    modelId = modelId[0:-1]\n",
    "    return modelId\n",
    "\n",
    "# add a modelId\n",
    "results[\"modelId\"] = generateModelId(estimators[estimatorId])\n",
    "results[\"modelIdNumber\"] = estimatorId\n",
    "                \n",
    "if not os.path.exists('results/'):\n",
    "    os.makedirs('results')\n",
    "results.to_csv(\"results/\"+str(estimatorId)+\".csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-purpose",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "file1 = open('output.log', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "\n",
    "\n",
    "estimatorErrors = []\n",
    "\n",
    "for line in Lines:\n",
    "    estimatorErrors.append(int(line[32:-11]))\n",
    "\n",
    "   \n",
    "\n",
    "with open('erstimatorErrors.txt', 'w') as f:\n",
    "    for e in estimatorErrors:\n",
    "        f.write(str(e)+\"\\n\")\n",
    "display(len(estimatorErrors))\n",
    "\n",
    "\n",
    "for e in estimatorErrors[0:125]:\n",
    "    display(str(e)+\": \"+str(estimators[e]))\n",
    "  \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-destination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

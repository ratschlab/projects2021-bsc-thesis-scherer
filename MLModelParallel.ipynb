{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "serial-choice",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] estimatorId\n",
      "ipykernel_launcher.py: error: argument estimatorId: invalid int value: '/home/david/.local/share/jupyter/runtime/kernel-779b8e2c-19a0-40ec-9187-78c4e401aa6a.json'\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras estimators: 2004\n",
      "Sklearn estimators: 0\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2476, in _get_value\n",
      "    result = type_func(arg_string)\n",
      "ValueError: invalid literal for int() with base 10: '/home/david/.local/share/jupyter/runtime/kernel-779b8e2c-19a0-40ec-9187-78c4e401aa6a.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1851, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2063, in _parse_known_args\n",
      "    stop_index = consume_positionals(start_index)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2019, in consume_positionals\n",
      "    take_action(action, args)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1912, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2443, in _get_values\n",
      "    value = self._get_value(action, arg_string)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2489, in _get_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument estimatorId: invalid int value: '/home/david/.local/share/jupyter/runtime/kernel-779b8e2c-19a0-40ec-9187-78c4e401aa6a.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-0f08d0321e63>\", line 451, in <module>\n",
      "    args = parser.parse_args()\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1818, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 1854, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2575, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/usr/lib/python3.9/argparse.py\", line 2562, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/david/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/david/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '/home/david/.local/share/jupyter/runtime/kernel-779b8e2c-19a0-40ec-9187-78c4e401aa6a.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[0;31m# consume any positionals following the last Optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m         \u001b[0mstop_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconsume_positionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mconsume_positionals\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2018\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0marg_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2019\u001b[0;31m                 \u001b[0mtake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[0;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[1;32m   1911\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1912\u001b[0;31m             \u001b[0margument_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[0;34m(self, action, arg_strings)\u001b[0m\n\u001b[1;32m   2442\u001b[0m             \u001b[0marg_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2443\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, action, arg_string)\u001b[0m\n\u001b[1;32m   2488\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid %(type)s value: %(value)r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument estimatorId: invalid int value: '/home/david/.local/share/jupyter/runtime/kernel-779b8e2c-19a0-40ec-9187-78c4e401aa6a.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0f08d0321e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"estimatorId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"computes estimator with given id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0mestimatorId\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimatorId\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2574\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2575\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.9/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2052\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2054\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2055\u001b[0m                                                                      value))\n\u001b[1;32m   2056\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "from joblib import dump, load\n",
    "from datetime import timedelta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import lightgbm as lightgbm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data preperation\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "data = pd.read_csv(\"completedata.csv\")\n",
    "numberOfInputWeeks = 3\n",
    "outputCategories = [\n",
    "                  'case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity',\n",
    "                  'testPositvity_7dayAverageBoth',    \n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage',    \n",
    "                   ]\n",
    "numberOfOutputs = len(outputCategories)\n",
    "numberOfPreComputedOutputWeeks = 4\n",
    "split = numberOfOutputs * numberOfPreComputedOutputWeeks + 2\n",
    "train_features = data[data['category']=='train'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "train_labels = data[data['category']=='train'].iloc[:,-split:-2]\n",
    "validation1_features = data[data['category']=='validation 1'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation1_labels = data[data['category']=='validation 1'].iloc[:,-split:-2]\n",
    "validation2_features = data[data['category']=='validation 2'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "validation2_labels = data[data['category']=='validation 2'].iloc[:,-split:-2]\n",
    "\n",
    "pip = Pipeline([('minmax_scaler', MinMaxScaler())])\n",
    "X_train = pip.fit_transform(train_features[train_features.columns].values)\n",
    "X_valid1 = pip.transform(validation1_features[train_features.columns].values)\n",
    "X_valid2 = pip.transform(validation2_features[train_features.columns].values)\n",
    "\n",
    "\n",
    "\n",
    "# estimator list generation\n",
    "\n",
    "numberOfOutputsForMultiOutput = numberOfPreComputedOutputWeeks\n",
    "epochs = 1000\n",
    "batch_size = 32 #16\n",
    "\n",
    "'''\n",
    "def getNormalKerasModel(name, learningrate, nrOfNeurons, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(input_)\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(hidden1) if isMultiOutput else keras.layers.Dense(1)(hidden1)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "\n",
    "def getDropoutKerasModel(name, learningrate, nrOfNeurons, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(input_)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden1)\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(dropout1) if isMultiOutput else keras.layers.Dense(1)(dropout1)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def getRegularizedKerasModel(name, learningrate, nrOfNeurons, alpha, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(alpha))(input_)\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(hidden1) if isMultiOutput else keras.layers.Dense(1)(hidden1)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def getTwoWayKerasModel(name, learningrate, nrOfNeurons, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(input_)\n",
    "    concat = keras.layers.Concatenate()([input_,hidden1])\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def getComplexKerasModel(name, learningrate, nrOfNeurons1, nrOfNeurons2, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons1, activation=\"relu\")(input_)\n",
    "    hidden2 = keras.layers.Dense(nrOfNeurons2, activation=\"relu\")(hidden1)\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(hidden1) if isMultiOutput else keras.layers.Dense(1)(hidden2)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def getTwoWayComplexDropoutKerasModel(name, learningrate, nrOfNeurons1, nrOfNeurons2, nrOfNeurons3, nrOfNeurons4, nrOfNeurons5, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons1, activation=\"relu\")(input_)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(nrOfNeurons2, activation=\"relu\")(hidden1)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(nrOfNeurons3, activation=\"relu\")(hidden2)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(nrOfNeurons4, activation=\"relu\")(hidden3)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden4)\n",
    "    hidden5 = keras.layers.Dense(nrOfNeurons5, activation=\"relu\")(hidden4)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.5)(hidden5)\n",
    "    concat = keras.layers.Concatenate()([input_,dropout1])\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def getDeepDropoutKerasModel(name, learningrate, nrOfNeurons, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=0.3)(input_)\n",
    "    hidden1 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=0.3)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=0.3)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=0.3)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=0.3)(hidden4)\n",
    "    hidden5 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout4)\n",
    "    dropout5 = keras.layers.Dropout(rate=0.3)(hidden5)\n",
    "    hidden6 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout5)\n",
    "    dropout6 = keras.layers.Dropout(rate=0.3)(hidden6)\n",
    "    hidden7 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout6)\n",
    "    dropout7 = keras.layers.Dropout(rate=0.3)(hidden7)\n",
    "    hidden8 = keras.layers.Dense(nrOfNeurons, activation=\"relu\")(dropout7)\n",
    "    dropout8 = keras.layers.Dropout(rate=0.3)(hidden8)\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(dropout8) if isMultiOutput else keras.layers.Dense(1)(dropout8)\n",
    "    model = keras.Model(name=name, inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def generic1(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    \n",
    "    lastHidden = dropout1\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic2(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    \n",
    "    lastHidden = dropout2\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic3(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    \n",
    "    lastHidden = dropout3\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic4(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=dropout)(hidden3)\n",
    "    \n",
    "    lastHidden = dropout4\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic5(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=dropout)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout4)\n",
    "    dropout5 = keras.layers.Dropout(rate=dropout)(hidden4)\n",
    "    \n",
    "    lastHidden = dropout5\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic6(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=dropout)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout4)\n",
    "    dropout5 = keras.layers.Dropout(rate=dropout)(hidden4)\n",
    "    hidden5 = keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout5)\n",
    "    dropout6 = keras.layers.Dropout(rate=dropout)(hidden5)\n",
    "    \n",
    "    lastHidden = dropout6\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic7(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=dropout)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout4)\n",
    "    dropout5 = keras.layers.Dropout(rate=dropout)(hidden4)\n",
    "    hidden5 = keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout5)\n",
    "    dropout6 = keras.layers.Dropout(rate=dropout)(hidden5)\n",
    "    hidden6 = keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout6)\n",
    "    dropout7 = keras.layers.Dropout(rate=dropout)(hidden6)\n",
    "    \n",
    "    lastHidden = dropout7\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic8(learningrate, hiddenLayers, dropout, l1, l2, isTwoWay, isMultiOutput):\n",
    "    input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "    dropout0 = keras.layers.Dropout(rate=dropout)(input_)\n",
    "    \n",
    "    hidden0 = keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout0)\n",
    "    dropout1 = keras.layers.Dropout(rate=dropout)(hidden0)\n",
    "    hidden1 = keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout1)\n",
    "    dropout2 = keras.layers.Dropout(rate=dropout)(hidden1)\n",
    "    hidden2 = keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout2)\n",
    "    dropout3 = keras.layers.Dropout(rate=dropout)(hidden2)\n",
    "    hidden3 = keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout3)\n",
    "    dropout4 = keras.layers.Dropout(rate=dropout)(hidden3)\n",
    "    hidden4 = keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout4)\n",
    "    dropout5 = keras.layers.Dropout(rate=dropout)(hidden4)\n",
    "    hidden5 = keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout5)\n",
    "    dropout6 = keras.layers.Dropout(rate=dropout)(hidden5)\n",
    "    hidden6 = keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout6)\n",
    "    dropout7 = keras.layers.Dropout(rate=dropout)(hidden6)\n",
    "    hidden7 = keras.layers.Dense(hiddenLayers[7], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2))(dropout7)\n",
    "    dropout8 = keras.layers.Dropout(rate=dropout)(hidden7)\n",
    "    \n",
    "    lastHidden = dropout8\n",
    "    concat = keras.layers.Concatenate()([input_,lastHidden]) if isTwoWay else lastHidden\n",
    "    output = keras.layers.Dense(numberOfOutputsForMultiOutput)(concat) if isMultiOutput else keras.layers.Dense(1)(concat)\n",
    "    model = keras.Model(inputs=[input_],outputs=[output])\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def genericKerasModel(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput):\n",
    "    if len(hiddenLayers) == 1:\n",
    "        return generic1(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 2:\n",
    "        return generic2(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 3:\n",
    "        return generic3(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 4:\n",
    "        return generic4(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 5:\n",
    "        return generic5(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 6:\n",
    "        return generic6(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    elif len(hiddenLayers) == 7:\n",
    "        return generic7(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "    else:\n",
    "        return generic8(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isTwoWay, isMultioutput)\n",
    "\n",
    "estimators = []\n",
    "estimatorNames = []\n",
    "\n",
    "# keras multi\n",
    "'''\n",
    "for learningrate in [0.001,0.0001,0.00001]:\n",
    "        estimators.append(getNormalKerasModel(\"normal_learningrate_\"+str(learningrate), learningrate, 100, True))\n",
    "        estimators.append(getNormalKerasModel(\"normal_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(200), learningrate, 200, True))\n",
    "        estimators.append(getDropoutKerasModel(\"dropout_learningrate_\"+str(learningrate), learningrate, 100, True))\n",
    "        estimators.append(getDropoutKerasModel(\"dropout_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(200), learningrate, 200, True))\n",
    "        estimators.append(getTwoWayKerasModel(\"twoway_learningrate_\"+str(learningrate), learningrate, 100, True))\n",
    "        estimators.append(getTwoWayKerasModel(\"twoway_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(200), learningrate, 200, True))\n",
    "        estimators.append(getComplexKerasModel(\"complex_learningrate_\"+str(learningrate), learningrate, 100, 10, True))\n",
    "        estimators.append(getComplexKerasModel(\"complex_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(200)+\"_\"+str(20), learningrate, 200, 20, True))\n",
    "        estimators.append(getTwoWayComplexDropoutKerasModel(\"twowaycomplexdropout_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size), learningrate, 200, 150, 100, 50, 10, True))\n",
    "        estimators.append(getTwoWayComplexDropoutKerasModel(\"twowaycomplexdropout_learningrate_\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(300)+\"_\"+str(150)+\"_\"+str(100)+\"_\"+str(50)+\"_\"+str(20), learningrate, 300, 150, 100, 50, 20, True))\n",
    "        estimators.append(getDeepDropoutKerasModel(\"DeepDropout\"+str(learningrate)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(100), learningrate, 100, True))\n",
    "        for alpha in [0.1,0.01, 0.001, 0.0001]: \n",
    "            estimators.append(getRegularizedKerasModel(\"regularized_learningrate_\"+str(learningrate)+\"_alpha_\"+str(alpha)+\"_batchsize_\"+str(batch_size), learningrate, 100, alpha, True))     \n",
    "            estimators.append(getRegularizedKerasModel(\"regularized_learningrate_\"+str(learningrate)+\"_alpha_\"+str(alpha)+\"_batchsize_\"+str(batch_size)+\"_neuronr_\"+str(200), learningrate, 200, alpha, True))             \n",
    "'''\n",
    "for lr in [0.001,0.0001]:\n",
    "    for dropoutV in [0,0.3,0.5]: # 0.4\n",
    "        for l1reg in [0.0001, 0.001, 0.01,0.1, 1, 0, 10]:\n",
    "            for l2reg in [0.0001, 0.001, 0.01,0.1, 1, 0, 10]: #\n",
    "                for twoWay in [True, False]:\n",
    "                    for hiddenL in [\n",
    "                                    [100],\n",
    "                                    [150],\n",
    "                                    [300]\n",
    "                                   ]:\n",
    "                        for multi in [True]:\n",
    "                            name = \"lr=\"+str(lr)+\"_\"+\"hl=\"+str(hiddenL)+\"_\"+\"do=\"+str(dropoutV)+\"_\"+\"l1=\"+str(l1reg)+\"_\"+\"l2=\"+str(l2reg)+\"_\"+\"tw=\"+str(twoWay)+\"_\"+\"mo=\"+str(multi)\n",
    "                            estimatorNames.append(name)\n",
    "                            estimators.append(genericKerasModel(lr,hiddenL,dropoutV, l1reg, l2reg, twoWay, multi))\n",
    "\n",
    "for lr in [0.001,0.0001]:\n",
    "    for dropoutV in [0,0.3,0.5]: \n",
    "        for l1reg in [0.0001, 0.01]:  \n",
    "            for l2reg in [10]: \n",
    "                for twoWay in [True, False]:\n",
    "                    for hiddenL in [[50],\n",
    "                                    [200],\n",
    "                                    [200,100],\n",
    "                                    [100, 50],\n",
    "                                    [200, 100, 50],\n",
    "                                    [200, 150, 100, 50],\n",
    "                                    [200, 150, 100, 75, 50],\n",
    "                                    [200, 150, 100, 90, 80, 50],\n",
    "                                    [200, 150, 100, 90, 80, 70, 50],\n",
    "                                    [400, 200, 100, 90, 80, 70, 60, 50]\n",
    "                                   ]:\n",
    "                        for multi in [True]:\n",
    "                            name = \"lr=\"+str(lr)+\"_\"+\"hl=\"+str(hiddenL)+\"_\"+\"do=\"+str(dropoutV)+\"_\"+\"l1=\"+str(l1reg)+\"_\"+\"l2=\"+str(l2reg)+\"_\"+\"tw=\"+str(twoWay)+\"_\"+\"mo=\"+str(multi)\n",
    "                            estimatorNames.append(name)\n",
    "                            estimators.append(genericKerasModel(lr,hiddenL,dropoutV, l1reg, l2reg, twoWay, multi))\n",
    "\n",
    "\n",
    "\n",
    "numberOfKerasEstimator = len(estimators)\n",
    "print(\"Keras estimators: \" + str(numberOfKerasEstimator))\n",
    "\n",
    "# sklearn multi\n",
    "'''\n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,0,1,10, 100]: \n",
    "    estimators.append(linear_model.Lasso(alpha=alpha))\n",
    "    estimators.append(linear_model.Ridge(alpha=alpha))\n",
    "\n",
    "kernels = ['linear','poly','polynomial','rbf','laplacian','sigmoid','cosine']\n",
    "for alpha in [0.01,0.1,10]:\n",
    "    for k in kernels:\n",
    "        estimators.append(KernelRidge(kernel=k, alpha=alpha))\n",
    "\n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,1,10]: \n",
    "    estimators.append(linear_model.MultiTaskLasso(alpha=alpha))\n",
    "\n",
    "\n",
    "for alpha in [0.00001, 0.0001,0.001,0.01,0.1,1,10]:\n",
    "    for layer in [\n",
    "        (20),\n",
    "        (100),\n",
    "        (20,20),\n",
    "        (100,10),\n",
    "        (100,50,10),\n",
    "        (100,100,10),\n",
    "    ]:\n",
    "        estimators.append(MLPRegressor(hidden_layer_sizes=layer, alpha=alpha, max_iter=1000))\n",
    "\n",
    "for nrOfEstimators in [100,200,500]: \n",
    "    for maxdepth in [None, 2, 4]:\n",
    "        for mss in [2,3,4]:\n",
    "            for msl in [1,2,3]:\n",
    "                estimators.append(RandomForestRegressor(n_estimators=nrOfEstimators, \n",
    "                                                        max_depth=maxdepth, \n",
    "                                                        min_samples_split=mss, \n",
    "                                                        min_samples_leaf=msl,\n",
    "                                                        n_jobs=-1))\n",
    "\n",
    "\n",
    "'''\n",
    "# training\n",
    "numberOfSklearnEstimator = len(estimators) - numberOfKerasEstimator\n",
    "print(\"Sklearn estimators: \" + str(numberOfSklearnEstimator))\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"estimatorId\", help=\"computes estimator with given id\",type=int)\n",
    "args = parser.parse_args()\n",
    "estimatorId = args.estimatorId\n",
    "'''\n",
    "estimatorId = 0\n",
    "\n",
    "\n",
    "else:\n",
    "    for category in outputCategories:\n",
    "        y_train = train_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]].values\n",
    "        reg = estimator.fit(X_train, y_train)\n",
    "\n",
    "        predictions_valid1 = pd.DataFrame(reg.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\" + str(numberOfOutputWeeks)+\"_\"+category for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]) \n",
    "        predictions_valid2 = pd.DataFrame(reg.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\" + str(numberOfOutputWeeks)+\"_\"+category for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)])\n",
    "\n",
    "        valid1Output = validation1_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]]\n",
    "        valid2Output = validation2_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]]\n",
    "\n",
    "        for outputWeekNumber in range(0,numberOfPreComputedOutputWeeks):\n",
    "            rmse1 = np.sqrt(mean_squared_error(predictions_valid1[\"pred_week_\" + str(outputWeekNumber)+\"_\"+category], valid1Output[\"output_\"+category+\"_\"+str(outputWeekNumber)]))\n",
    "            rmse2 = np.sqrt(mean_squared_error(predictions_valid2[\"pred_week_\" + str(outputWeekNumber)+\"_\"+category], valid2Output[\"output_\"+category+\"_\"+str(outputWeekNumber)]))\n",
    "\n",
    "            d = {'model':[reg],'model type': [\"sklearn_multi_weeks_output\"],'target':[category],'week':[outputWeekNumber], 'model rsme 1':[rmse1], 'model rsme 2':[rmse2]}\n",
    "            df = pd.DataFrame(data=d)\n",
    "            df.to_csv(\"results.csv\",mode='a', header=False, index=False)\n",
    "'''\n",
    "\n",
    "estimator = estimators[estimatorId]\n",
    "\n",
    "#if (str(type(estimator)) == \"<class 'tensorflow.python.keras.engine.functional.Functional'>\"):\n",
    "for category in outputCategories:\n",
    "    y_train = train_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]].values\n",
    "    y_valid1 = validation1_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]].values \n",
    "    estimator.fit(X_train, \n",
    "                  y_train, \n",
    "                  batch_size=batch_size, \n",
    "                  epochs=epochs, \n",
    "                  verbose=0, \n",
    "                  validation_data=(X_valid1,y_valid1), \n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "    predictions_valid1 = pd.DataFrame(estimator.predict(X_valid1), index=validation1_labels.index, columns=[\"pred_week_\" + str(numberOfOutputWeeks)+\"_\"+category for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]) \n",
    "    predictions_valid2 = pd.DataFrame(estimator.predict(X_valid2), index=validation2_labels.index, columns=[\"pred_week_\" + str(numberOfOutputWeeks)+\"_\"+category for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)])\n",
    "\n",
    "    valid1Output = validation1_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]]\n",
    "    valid2Output = validation2_labels[[\"output_\"+category+\"_\"+str(numberOfOutputWeeks) for numberOfOutputWeeks in range(0,numberOfPreComputedOutputWeeks)]]\n",
    "\n",
    "    for outputWeekNumber in range(0,numberOfPreComputedOutputWeeks):\n",
    "        rmse1 = np.sqrt(mean_squared_error(predictions_valid1[\"pred_week_\" + str(outputWeekNumber)+\"_\"+category], valid1Output[\"output_\"+category+\"_\"+str(outputWeekNumber)]))\n",
    "        rmse2 = np.sqrt(mean_squared_error(predictions_valid2[\"pred_week_\" + str(outputWeekNumber)+\"_\"+category], valid2Output[\"output_\"+category+\"_\"+str(outputWeekNumber)]))\n",
    "\n",
    "        d = {'model':estimatorNames[estimatorId],'model type': [\"keras_multi_weeks_output\"],'target':[category],'week':[outputWeekNumber], 'model rsme 1':[rmse1], 'model rsme 2':[rmse2]}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        df.to_csv(\"results.csv\",mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-purpose",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

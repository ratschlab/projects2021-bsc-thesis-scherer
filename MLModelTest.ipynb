{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FILE WAS USED TO TEST THE SELECTED MODEL ON THE TEST SET\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "from joblib import dump, load\n",
    "from datetime import timedelta\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import xgboost as xgb\n",
    "import lightgbm as lightgbm\n",
    "\n",
    "# settings:\n",
    "numberOfInputWeeks = 3 # must be equal to the number of input weeks set in data preperator\n",
    "numberOfOutputWeeks = 4 # must be equal to the number of output week set in data preperator\n",
    "\n",
    "\n",
    "\n",
    "# data preperation\n",
    "cantonKeys = ['AG','AI','AR', 'BE', 'BL', 'BS', 'FR', 'GE', 'GL', 'GR', 'JU', 'LU', 'NE', 'NW', 'OW', 'SG', 'SH', 'SO', 'SZ', 'TG', 'TI', 'UR', 'VD', 'VS', 'ZG','ZH']\n",
    "data = pd.read_csv(\"completedata.csv\")\n",
    "\n",
    "\n",
    "outputCategories = ['case_inz_entries_7dayAverage',\n",
    "                  'hosp_inz_entries_7dayAverage',\n",
    "                  'death_inz_entries_7dayAverage',\n",
    "                  'testPositvity_7dayAverage',\n",
    "                  'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                  'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "                   ]\n",
    "numberOfOutputs = len(outputCategories)\n",
    "\n",
    "split = numberOfOutputs * numberOfOutputWeeks + 2\n",
    "\n",
    "train_features = data[(data['category']=='train') | (data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "train_labels = data[(data['category']=='train') | (data['category']=='validation 1') | (data['category']=='validation 2')].iloc[:,-split:-2]\n",
    "\n",
    "test1_features = data[data['category']=='test 1'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "test1_labels = data[data['category']=='test 1'].iloc[:,-split:-2]\n",
    "test2_features = data[data['category']=='test 2'].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "test2_labels = data[data['category']=='test 2'].iloc[:,-split:-2]\n",
    "test1And2_labels = data[(data['category']=='test 1') | (data['category']=='test 2')].iloc[:,-split:-2]\n",
    "test1And2_features = data[(data['category']=='test 1') | (data['category']=='test 2')].iloc[:,0:-split].drop(['lastInputDay'], axis=1)\n",
    "\n",
    "pip = Pipeline([('minmax_scaler', MinMaxScaler())])\n",
    "X_train = pip.fit_transform(train_features[train_features.columns].values)\n",
    "X_test1 = pip.transform(test1_features[train_features.columns].values)\n",
    "X_test2 = pip.transform(test2_features[train_features.columns].values)\n",
    "X_test1And2 = pip.transform(test1And2_features[train_features.columns].values)\n",
    "\n",
    "\n",
    "    \n",
    "def generic1(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "def generic2(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic3(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic4(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic5(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic6(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic7(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "\n",
    "def generic8(learningrate, hiddenLayers, dropout, l1, l2, isMultiOutput):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Dense(hiddenLayers[0], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2), input_shape=X_train.shape[1:]))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[1], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[2], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[3], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[4], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[5], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[6], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(hiddenLayers[7], activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(l1=l1, l2=l2)))\n",
    "    model.add(keras.layers.Dropout(rate=dropout))\n",
    "    model.add(keras.layers.Dense(numberOfOutputWeeks) if isMultiOutput else keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learningrate))\n",
    "    return model\n",
    "    \n",
    "\n",
    "    \n",
    "def genericKerasModel(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput):\n",
    "    if len(hiddenLayers) == 1:\n",
    "        return generic1(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 2:\n",
    "        return generic2(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 3:\n",
    "        return generic3(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 4:\n",
    "        return generic4(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 5:\n",
    "        return generic5(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 6:\n",
    "        return generic6(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    elif len(hiddenLayers) == 7:\n",
    "        return generic7(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)\n",
    "    else:\n",
    "        return generic8(learningrate, hiddenLayers, dropout, l1regularization, l2regularization, isMultioutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "numberOfEstimators = 0\n",
    "results = pd.DataFrame()\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"jobnr\", help=\"computes job\",type=int)\n",
    "args = parser.parse_args()\n",
    "jobnr = args.jobnr\n",
    "'''\n",
    "jobnr = 99\n",
    "\n",
    "\n",
    "# Test\n",
    "\n",
    "# 'case_inz_entries_7dayAverage'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"MultiTaskLasso\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"alpha\": 0.7,\n",
    "                      \"tol\": 1e-05,\n",
    "                      \"task\":'case_inz_entries_7dayAverage',\n",
    "                  }\n",
    "                )\n",
    "\n",
    "\n",
    "# 'hosp_inz_entries_7dayAverage'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"MultiTaskLasso\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"alpha\": 0.014,\n",
    "                      \"tol\": 0.0001,\n",
    "                      \"task\":'hosp_inz_entries_7dayAverage',\n",
    "                  }\n",
    "                )\n",
    "\n",
    "\n",
    "# 'death_inz_entries_7dayAverage'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"Lasso\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"tol\": 0.0001,\n",
    "                      \"alpha\": 0.0009,\n",
    "                      \"task\":'death_inz_entries_7dayAverage',\n",
    "                  }\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "# 'testPositvity_7dayAverageBoth'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"Keras\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"hiddenLayers\": [350, 175, 85],\n",
    "                      \"numberOfhiddenLayers\": 3,\n",
    "                      \"isTwoWay\": False,\n",
    "                      \"l1reg\": 0,\n",
    "                      \"alpha\": 0.0001,\n",
    "                      \"dropoutValue\": 0,\n",
    "                      \"learningRate\": 0.0001,\n",
    "                      \"task\":'testPositvity_7dayAverage',\n",
    "                      \"epochs\":73\n",
    "                  }\n",
    "                )\n",
    "\n",
    "\n",
    "# 'workplaces_percent_change_from_baseline_7dayAverage'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"RandomForrest\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"n_estimators\": 1000,\n",
    "                      \"max_features\": 'auto',\n",
    "                      \"min_samples_leaf\": 8,\n",
    "                      \"task\":'workplaces_percent_change_from_baseline_7dayAverage',\n",
    "                  }\n",
    "                )\n",
    "\n",
    "# 'transit_stations_percent_change_from_baseline_7dayAverage'\n",
    "estimators.append({\n",
    "                      \"modelClass\": \"Keras\",\n",
    "                      \"isMultiWeek\": True,\n",
    "                      \"hiddenLayers\": [500, 250],\n",
    "                      \"numberOfhiddenLayers\": 2,\n",
    "                      \"isTwoWay\": False,\n",
    "                      \"l1reg\": 0.001,\n",
    "                      \"alpha\": 0.0001,\n",
    "                      \"dropoutValue\": 0.5,\n",
    "                      \"learningRate\": 0.0001,\n",
    "                      \"task\":'transit_stations_percent_change_from_baseline_7dayAverage',\n",
    "                      \"epochs\":94\n",
    "                  }\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# constructs and saves the results of a fitted estimator    \n",
    "def constructResults(estimator, task, numberOfRanEpochs):\n",
    "    # predictions for all weeks\n",
    "    predictions1 = pd.DataFrame(estimator.predict(X_test1), index=test1_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]) \n",
    "    predictions2 = pd.DataFrame(estimator.predict(X_test2), index=test2_labels.index, columns=[\"pred_week_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)])\n",
    "\n",
    "    # test for all weeks\n",
    "    y_test1 = test1_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "    y_test2 = test2_labels[[\"output_\"+task+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]]\n",
    "\n",
    "    resultsDf = pd.DataFrame()\n",
    "    # compute and safe results for every week\n",
    "    for outputWeekNumber in range(0,numberOfOutputWeeks):\n",
    "        # compute root mean squared error for test sets\n",
    "        rmse1 = np.sqrt(mean_squared_error(predictions1[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_test1[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        rmse2 = np.sqrt(mean_squared_error(predictions2[\"pred_week_\"+task+\"_\"+str(outputWeekNumber)], y_test2[\"output_\"+task+\"_\"+str(outputWeekNumber)]))\n",
    "        # safe the results and all model parameters\n",
    "        res = {}\n",
    "        if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "            res = {'modelId':[generateModelId(estimators[estimatorId])],\n",
    "                  'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"hiddenLayers\":[estimators[estimatorId][\"hiddenLayers\"]],\n",
    "                 \"numberOfhiddenLayers\":[len(estimators[estimatorId][\"hiddenLayers\"])],\n",
    "                 \"isTwoWay\": [estimators[estimatorId][\"isTwoWay\"]],\n",
    "                 \"l1reg\": [estimators[estimatorId][\"l1reg\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"dropoutValue\":[estimators[estimatorId][\"dropoutValue\"]],\n",
    "                 \"learningRate\":[estimators[estimatorId][\"learningRate\"]],\n",
    "                 \"numberOfRanEpochs\": [numberOfRanEpochs]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "            res = {'modelId':[generateModelId(estimators[estimatorId])],\n",
    "                   'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"n_estimators\": [estimators[estimatorId][\"n_estimators\"]],\n",
    "                 \"max_features\": [estimators[estimatorId][\"max_features\"]],\n",
    "                 \"min_samples_leaf\": [estimators[estimatorId][\"min_samples_leaf\"]]\n",
    "                }               \n",
    "        \n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "            res = {'modelId':[generateModelId(estimators[estimatorId])],\n",
    "                   'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "            res = {'modelId':[generateModelId(estimators[estimatorId])],\n",
    "                   'modelClass':[estimators[estimatorId][\"modelClass\"]],\n",
    "                 'task':[task],\n",
    "                 'week':[outputWeekNumber], \n",
    "                 'model rmse 1':[rmse1], \n",
    "                 'model rmse 2':[rmse2],\n",
    "                 'isMultiWeek':[estimators[estimatorId][\"isMultiWeek\"]],\n",
    "                 \"alpha\": [estimators[estimatorId][\"alpha\"]],\n",
    "                 \"tol\": [estimators[estimatorId][\"tol\"]]\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError('Tried to save results for an unsupported estimator')\n",
    "        resultsDf = resultsDf.append(pd.DataFrame(data=res), ignore_index = True)\n",
    "    return resultsDf\n",
    "   \n",
    "\n",
    "        \n",
    "def generateModelId(dictionary):\n",
    "    modelId = \"\"\n",
    "    for key in dictionary.keys():\n",
    "        modelId = modelId + key +\"=\"+ str(dictionary[key]) +\"/\"\n",
    "    modelId = modelId[0:-1]\n",
    "    return modelId    \n",
    "    \n",
    "\n",
    "# training\n",
    "\n",
    "\n",
    "for estimatorId in range(0,len(estimators)):\n",
    "\n",
    "    # get train labels for all weeks\n",
    "    y_train = train_labels[[\"output_\"+estimators[estimatorId][\"task\"]+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values\n",
    "    if estimators[estimatorId][\"modelClass\"] == \"Keras\":\n",
    "        # get test labels for all weeks (used for early stopping)\n",
    "        y_test1And2 = test1And2_labels[[\"output_\"+estimators[estimatorId][\"task\"]+\"_\"+str(outputWeekNumber) for outputWeekNumber in range(0,numberOfOutputWeeks)]].values \n",
    "        # construct Keras model\n",
    "\n",
    "        estimator = genericKerasModel(\n",
    "            estimators[estimatorId][\"learningRate\"],\n",
    "            estimators[estimatorId][\"hiddenLayers\"],\n",
    "            estimators[estimatorId][\"dropoutValue\"],\n",
    "            estimators[estimatorId][\"l1reg\"],\n",
    "            estimators[estimatorId][\"alpha\"],\n",
    "            estimators[estimatorId][\"isMultiWeek\"]\n",
    "        )\n",
    "\n",
    "        # fit Keras model\n",
    "        history = estimator.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=32, \n",
    "          epochs=estimators[estimatorId][\"epochs\"], \n",
    "          verbose=0)\n",
    "        \n",
    "        \n",
    "        if not os.path.exists('models/trainedOnTrainingAndValidationData/'):\n",
    "            os.makedirs('models')\n",
    "            os.makedirs('models/trainedOnTrainingAndValidationData/')\n",
    "        estimator.save(\"models/trainedOnTrainingAndValidationData/\"+str(jobnr)+\"_\"+estimators[estimatorId][\"task\"])\n",
    "        \n",
    "        \n",
    "        numberOfRanEpochs = len(history.history['loss'])\n",
    "        results = results.append(constructResults(estimator, estimators[estimatorId][\"task\"], numberOfRanEpochs), ignore_index = True)\n",
    "\n",
    "    elif estimators[estimatorId][\"modelClass\"] == \"RandomForrest\":\n",
    "        estimator = RandomForestRegressor(n_estimators=estimators[estimatorId][\"n_estimators\"], \n",
    "                                          max_features=estimators[estimatorId][\"max_features\"],\n",
    "                                          min_samples_leaf=estimators[estimatorId][\"min_samples_leaf\"],\n",
    "                                          n_jobs=-1\n",
    "                                         )\n",
    "        estimator.fit(X_train,y_train)\n",
    "        dump(estimator, \"models/trainedOnTrainingAndValidationData/\"+str(estimatorId)+\"_\"+estimators[estimatorId][\"task\"]+\"_sklearn.pkl\")\n",
    "        results = results.append(constructResults(estimator, estimators[estimatorId][\"task\"], -1), ignore_index = True)\n",
    "    elif estimators[estimatorId][\"modelClass\"] == \"Lasso\":\n",
    "        estimator = linear_model.Lasso(alpha=estimators[estimatorId][\"alpha\"],\n",
    "                                               tol = estimators[estimatorId][\"tol\"])\n",
    "        estimator.fit(X_train,y_train)\n",
    "        dump(estimator, \"models/trainedOnTrainingAndValidationData/\"+str(estimatorId)+\"_\"+estimators[estimatorId][\"task\"]+\"_sklearn.pkl\")\n",
    "        results = results.append(constructResults(estimator, estimators[estimatorId][\"task\"], -1), ignore_index = True)\n",
    "    elif estimators[estimatorId][\"modelClass\"] == \"MultiTaskLasso\":\n",
    "        estimator = linear_model.MultiTaskLasso(alpha = estimators[estimatorId][\"alpha\"],\n",
    "                                               tol = estimators[estimatorId][\"tol\"])\n",
    "        estimator.fit(X_train,y_train)\n",
    "        dump(estimator, \"models/trainedOnTrainingAndValidationData/\"+str(estimatorId)+\"_\"+estimators[estimatorId][\"task\"]+\"_sklearn.pkl\")\n",
    "        results = results.append(constructResults(estimator, estimators[estimatorId][\"task\"], -1), ignore_index = True)\n",
    "    else:\n",
    "        raise ValueError('Tried to fit an unsupported estimator')            \n",
    "    \n",
    "\n",
    "\n",
    "results['iteration'] = jobnr\n",
    "    \n",
    "\n",
    "if not os.path.exists('test_results/'):\n",
    "    os.makedirs('test_results')\n",
    "results.to_csv(\"test_results/\"+str(jobnr)+\".csv\", header=True, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
